{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device cuda:0\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import time\n",
    "import copy\n",
    "import math \n",
    "import re\n",
    "import json \n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "import pickle\n",
    "import random \n",
    "import pandas as pd\n",
    "\n",
    "from functools import partial \n",
    "\n",
    "cuda_available = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if cuda_available else \"cpu\")\n",
    "print(f'''using device {device}''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.OutputArea.auto_scroll_threshold = 9999;\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.auto_scroll_threshold = 9999;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cuda(input):\n",
    "    if torch.cuda.is_available(): return input.cuda()\n",
    "    return input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/r2/Documents/RNNexp\n"
     ]
    }
   ],
   "source": [
    "path = !pwd\n",
    "path = path[0]\n",
    "print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.read_pickle(path+\"/data/step3_DAT_MT_USDJPY_M1_2018_merged_pickled\") \n",
    "# data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Struct():\n",
    "    pass \n",
    "\n",
    "def load_trumpdata(datapath, pad_tok='¬£', start_tok='^', end_tok='‚Ç¨'):\n",
    "\n",
    "    van_tws, tws, van_tw_str, tw_str = [],[],'',''\n",
    "    filenames = ['condensed_2018.json', 'condensed_2016.json', 'condensed_2017.json', 'condensed_2018.json']\n",
    "    for fname in filenames:\n",
    "        f = open(datapath+fname,\"r\")\n",
    "        data = f.readline()\n",
    "        f.close()\n",
    "        data_tr = json.loads(data)\n",
    "        for line in range(0,len(data_tr)):\n",
    "            tweet      = data_tr[line][\"text\"].rstrip('\\\\')\n",
    "            van_tw_str = van_tw_str + tweet \n",
    "            van_tws.append(tweet)            \n",
    "    symbols = list(set(van_tw_str))  \n",
    "    assert(pad_tok   not in symbols)\n",
    "    assert(start_tok not in symbols)\n",
    "    assert(end_tok   not in symbols)\n",
    "\n",
    "    for tweet in van_tws:\n",
    "        pad_tweet = start_tok + tweet + end_tok\n",
    "        tw_str    = tw_str + pad_tweet            \n",
    "        tws.append(pad_tweet)        \n",
    "    symbols = [pad_tok, start_tok] + symbols + [end_tok]   \n",
    "    decoder = {idx: symbols[idx] for idx in range(0,len(symbols))}\n",
    "    encoder = {symbols[idx]: idx for idx in range(0,len(symbols))}        \n",
    "    return tws, tw_str, decoder, encoder\n",
    "\n",
    "def pp_trumpdata(filename, prop, bsize=1):\n",
    "    Data, train, valid, test = Struct(), Struct(), Struct(), Struct()        \n",
    "    tweets, tweet_str, Data.decoder, Data.encoder = load_trumpdata(filename)    \n",
    "\n",
    "    train.tweets = tweets[0:round(prop[0]*len(tweets))]\n",
    "    train.tweet_str = tweet_str[0:round(prop[1]*len(tweet_str))]    \n",
    "    valid.tweets = tweets[round(prop[0]*len(tweets)):round(prop[1]*len(tweets))]\n",
    "    valid.tweet_str = tweet_str[round(prop[0]*len(tweet_str)):round(prop[1]*len(tweet_str))]    \n",
    "    test.tweets  = tweets[round(prop[1]*len(tweets)):-1]\n",
    "    test.tweet_str  = tweet_str[round(prop[1]*len(tweet_str)):-1]    \n",
    "\n",
    "    train.batch_str = []\n",
    "    stepsize = round(len(train.tweet_str)/bsize-1)\n",
    "    for i in range(0,bsize):\n",
    "        train.batch_str.append(train.tweet_str[i*stepsize:(i+1)*stepsize])\n",
    "    valid.batch_str = [valid.tweet_str]\n",
    "    \n",
    "    Data.train, Data.valid, Data.test, Data.bsize = train, valid, test, bsize\n",
    "    return Data\n",
    "\n",
    "def save_checkpoint(state, filename='models/checkpoint.pth.tar'):\n",
    "    torch.save(state, filename)\n",
    "\n",
    "def load_checkpoint(filename='models/checkpoint.pth.tar'):\n",
    "    checkpoint = torch.load(filename)    \n",
    "    for item in iter(checkpoint):\n",
    "        print(item)\n",
    "    model = RNN(checkpoint['in_sz'],checkpoint['hd_sz'],checkpoint['out_sz'])\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    #     optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    epoch = checkpoint['epoch']\n",
    "    loss = checkpoint['loss']\n",
    "    return model, epoch, loss    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### encoder/decoders "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encodestr(string, encoder):\n",
    "    x = torch.zeros((len(string),len(encoder)))\n",
    "    x[[idx for idx in range(0,len(string))],[encoder[char] for char in string]] = 1\n",
    "    return x\n",
    "\n",
    "def onehencode(symbol, encoder):\n",
    "    x = torch.zeros(len(encoder),1)\n",
    "    x[encoder[symbol]] = 1.0\n",
    "    return x.t()\n",
    "\n",
    "def encode(string, encoder):\n",
    "    return torch.Tensor([encoder[char] for char in y_str])\n",
    "\n",
    "def onehdecode(X,decoder):\n",
    "    assert(X.shape[-1] == len(decoder))\n",
    "    string = ''\n",
    "    for char in range(X.shape[0]):\n",
    "        val, idx = torch.max(X[char],0)\n",
    "        string += decoder[idx.item()]\n",
    "    print(string)\n",
    "    \n",
    "def ydecode(Y,decoder):\n",
    "    string = ''\n",
    "    for char in range(Y.shape[0]): string += decoder[Y[char].item()]\n",
    "    print(string)\n",
    "\n",
    "def change_char(s, p, r):\n",
    "    return s[:p]+r+s[p+1:] \n",
    "\n",
    "def generate_seq(model,data,sql,symbol='^'):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        hidden = model.initHidden(1)\n",
    "        result = symbol\n",
    "        for i in range(sql):\n",
    "            x = cuda(onehencode(symbol,data.encoder))\n",
    "            output, hidden = model.forward(x,hidden)        \n",
    "            hidden = hidden.detach()\n",
    "            \n",
    "            prob     = np.exp(output[0].cpu().numpy())\n",
    "            cum_prob = np.cumsum(prob)\n",
    "            idx      = np.where(cum_prob - random.random() > 0)[0][0]\n",
    "            symbol   = data.decoder[idx]\n",
    "            result  += symbol\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^cR57BJ69YQ85I8160kSBYluÁî±se-hinwUSICHEIONT#Undtly0338200ÈùûvSh@Ivisht, CenSeVEuSySIS, @Vo,„ÅßICDON)RxxNNNYHWHERHS,@RuL‚úàuBdqu4ike8nersts üáßj:J!‚Ç¨OBy‚Ç¨vy◊ùrects byAme(V. lov\n",
      "WoGAL McKINARY ICAUohtoüéÑmI all„ÅãAmEfDE\n"
     ]
    }
   ],
   "source": [
    "generate_seq(learn.model,data,200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## my RNN module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNoriginal(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNNoriginal,self).__init__()\n",
    "        self.hd_sz  = hidden_size\n",
    "        self.in_sz  = input_size\n",
    "        self.out_sz = output_size\n",
    "        \n",
    "        self.h1  = nn.Linear(input_size + hidden_size, hidden_size)               \n",
    "        self.o1   = nn.Linear(input_size + hidden_size, input_size)\n",
    "\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "        \n",
    "    def forward(self, input, hidden):\n",
    "        combined = torch.cat((input, hidden), 1)    \n",
    "        \n",
    "        hidden   = self.h1(combined)\n",
    "        hidden   = torch.tanh(hidden)\n",
    "        \n",
    "        output   = self.o1(combined)\n",
    "        output   = self.softmax(output)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self,bs):\n",
    "        return cuda(torch.zeros(bs,self.hd_sz))\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNN,self).__init__()\n",
    "        \n",
    "        self.hd_sz  = hidden_size\n",
    "        self.in_sz  = input_size\n",
    "        self.out_sz = output_size\n",
    "        \n",
    "        combined = input_size+hidden_size\n",
    "        \n",
    "        self.h1      = nn.Linear(combined, hidden_size)               \n",
    "\n",
    "        self.o1      = nn.Linear(combined, combined)\n",
    "        self.bn1     = nn.BatchNorm1d(combined)\n",
    "        self.relu    = nn.ReLU(combined)\n",
    "\n",
    "        self.o2      = nn.Linear(combined, input_size)\n",
    "        self.bn2     = nn.BatchNorm1d(input_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "        \n",
    "    def forward(self, input, hidden):\n",
    "        combined = torch.cat((input, hidden), 1)    \n",
    "        \n",
    "        hidden   = self.h1(combined)\n",
    "        hidden   = torch.tanh(hidden)\n",
    "        \n",
    "        output   = self.o1(combined)\n",
    "        output   = self.bn1(output)\n",
    "        output   = self.relu(output)\n",
    "        \n",
    "        output   = self.o2(output)\n",
    "        output   = self.bn2(output)\n",
    "        output   = self.softmax(output)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self,bs):\n",
    "        return cuda(torch.zeros(bs,self.hd_sz))\n",
    "\n",
    "def weights_init_uniform(m):\n",
    "    classname = m.__class__.__name__\n",
    "    # for every Linear layer in a model..\n",
    "    if classname.find('Linear') != -1:\n",
    "        # apply a uniform distribution to the weights and a bias=0\n",
    "        m.weight.data.uniform_(0.0, 1.0)\n",
    "        m.bias.data.fill_(0)\n",
    "\n",
    "def weights_init_xavier(m):\n",
    "    classname = m.__class__.__name__\n",
    "    # for every Linear layer in a model..\n",
    "    if classname.find('Linear') != -1:\n",
    "        torch.nn.init.xavier_uniform_(m.weight)\n",
    "        m.bias.data.fill_(0.01)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataLoaders, Itterators, DataSets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad(str_list,sql=1,token='¬£'):\n",
    "    f\"\"\"pad all strings in a list to max_len\"\"\"\n",
    "    max_len = math.ceil(len(max(str_list, key=len))/sql)*sql\n",
    "    for idx, row in enumerate(str_list):        \n",
    "        str_list[idx] = row + token*(max_len-len(row))\n",
    "    if len(str_list) == 1: return str_list[0]\n",
    "    return str_list\n",
    "\n",
    "def mk_tweetbatch(tweets,encoder,bs,sql,symbol='¬£'):\n",
    "    assert(math.floor(len(tweets)/bs)==len(tweets)/bs)\n",
    "    bch       = batch_strings(tweets,bs,sql)[0]\n",
    "    assert(math.floor(len(bch[0])/sql)==len(bch[0])/sql)            \n",
    "    n_segment = int(len(bch[0])/sql)\n",
    "    sbx       = torch.zeros(bs,n_segment,sql,len(encoder))\n",
    "    sby       = torch.zeros(bs,n_segment,sql).long()\n",
    "    for tweet in range(bs):\n",
    "        \"\"\"for target we don't use first char, compensate with one padded char\"\"\"\n",
    "        y_str = bch[tweet][1:len(bch[tweet])]+symbol      \n",
    "        \n",
    "        chng_pos = len(bch[tweet])\n",
    "        \"\"\"if we find padded char, we know that tweet ended, remove last char of tweet\"\"\"        \n",
    "        if re.search(symbol,bch[tweet]): chng_pos = re.search(symbol,bch[tweet]).span()[0]       \n",
    "        x_str = change_char(bch[tweet],chng_pos-1,symbol)     \n",
    "        \n",
    "        for segment in range(n_segment):\n",
    "            x = x_str[sql*segment:sql*(segment+1)]\n",
    "            y = y_str[sql*segment:sql*(segment+1)]  \n",
    "            sbx[tweet,segment] = encodestr(x,encoder)\n",
    "            sby[tweet,segment] = torch.Tensor([encoder[char] for char in y])                    \n",
    "    return sbx,sby\n",
    "\n",
    "class TweetDataLoader():\n",
    "    def __init__(self,data,tweets,bs,sql,shuffle=False):    \n",
    "        assert(math.floor(len(tweets)/bs)==len(tweets)/bs)\n",
    "        self.tweets  = tweets\n",
    "        self.bs      = bs         \n",
    "        self.sql     = sql\n",
    "        self.encoder = data.encoder\n",
    "        self.i       = -1\n",
    "        self.shuffle = shuffle        \n",
    "        \n",
    "    def __iter__(self):  \n",
    "        self.i = -1\n",
    "        while True:\n",
    "            self.i+=1\n",
    "            twt      = self.tweets[self.i*self.bs:(self.i+1)*self.bs]\n",
    "            sbx,sby  = mk_tweetbatch(twt,self.encoder,self.bs,self.sql)\n",
    "            sbloader = iter(SBDataLoader(sbx,sby))            \n",
    "            try:\n",
    "                while True:                \n",
    "                    yield next(sbloader) \n",
    "            except StopIteration:\n",
    "                pass            \n",
    "            if self.i==round(len(self.tweets)/self.bs)-1:\n",
    "                if self.shuffle: \n",
    "                    random.shuffle(self.tweets)\n",
    "                    self.i = -1\n",
    "                break\n",
    "\n",
    "class SBDataLoader():\n",
    "    def __init__(self, sbx, sby): \n",
    "        self.sbx, self.sby = sbx, sby\n",
    "    def __iter__(self):\n",
    "        for j in range(self.sbx.shape[1]): yield cuda(self.sbx[:,j]), cuda(self.sby[:,j])\n",
    "\n",
    "def batch_strings(tweets,bs,sql=1):\n",
    "    f\"\"\"creates a list of batchsize-list of strings of same length and sort each batch with longest string first.\"\"\"    \n",
    "    \"\"\"NOT SURE ABOUT THIS OFFSET, BUT THE PREVIOUS CODE ALWAYS MADE A 0\"\"\"\n",
    "    offset = -1*((len(tweets)/bs)*10%2!=0)    \n",
    "#     offset = -1*((math.floor(len(tweets)/bs)==len(tweets)/bs)==0)    \n",
    "    bch_strs = [] \n",
    "    for i in range(round(len(tweets)/bs)+offset):\n",
    "        strings = tweets[i*bs:(i+1)*bs]\n",
    "        strings.sort(key=len,reverse=True)\n",
    "        pad_strings = pad(strings,sql)\n",
    "        bch_strs.append(pad_strings)\n",
    "    return bch_strs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### building FastAI classes to be used with callbacks in future\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Learner():\n",
    "    def __init__(self, model, loss_fn, data,lr):\n",
    "        opt = optim.RMSprop(model.parameters(), lr)\n",
    "        assert(model is not None)\n",
    "        assert(loss_fn is not None)\n",
    "        assert(data is not None)\n",
    "        self.model,self.opt,self.loss_fn,self.data = model,opt,loss_fn,data\n",
    "        \n",
    "\n",
    "class Callback():\n",
    "    def begin_fit(self,learn):\n",
    "        self.learn = learn\n",
    "        return True\n",
    "    def after_fit(self): return True\n",
    "    def begin_epoch(self,epoch):\n",
    "        self.epoch=epoch\n",
    "        return True\n",
    "    def begin_validate(self): return True\n",
    "    def after_epoch(self): return True \n",
    "    def begin_batch(self,xb,yb):\n",
    "        self.xb,self.yb = xb,yb\n",
    "        return True\n",
    "    def after_loss(self,loss):\n",
    "        self.loss=loss\n",
    "        return True\n",
    "    def after_backward(self): return True\n",
    "    def after_step(self): return True\n",
    "\n",
    "class TrainEvalCallback(Callback):\n",
    "    def begin_fit(self):\n",
    "        self.run.n_epochs=0.\n",
    "        self.run.n_iter=0\n",
    "    \n",
    "    def after_batch(self):\n",
    "        if not self.in_train: return\n",
    "        self.run.n_epochs += 1./self.iters\n",
    "        self.run.n_iter   += 1\n",
    "        \n",
    "    def begin_epoch(self):\n",
    "        self.run.n_epochs=self.epoch\n",
    "        self.model.train()\n",
    "        self.run.in_train=True\n",
    "\n",
    "    def begin_validate(self):\n",
    "        self.model.eval()\n",
    "        self.run.in_train=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_rnn(epoches, learn, data, valid_loss=[], cb=None):\n",
    "    start = time.time()\n",
    "    for e in range(epoches):\n",
    "        i = 0\n",
    "        for xb, yb in data.train_dl:      \n",
    "            learn.model.train()\n",
    "            if xb[0,0,1].item() == 1: hidden = learn.model.initHidden(xb.shape[0])                \n",
    "            learn, hidden, loss = one_rnn_batch(learn,xb,yb,hidden)           \n",
    "            if (i%100==0): valid_loss.append(get_valid(learn,data))\n",
    "            i += 1\n",
    "    return learn, hidden, valid_loss\n",
    "\n",
    "def one_rnn_batch(learn,xb,yb,hidden):\n",
    "    loss = 0 \n",
    "    for char in range(xb.shape[1]):\n",
    "        x,y = xb[:,char],yb[:,char]\n",
    "\n",
    "        idx    = zero_idx(y)\n",
    "        if idx is None: break\n",
    "\n",
    "        hidden = hidden[idx]\n",
    "        x      = x[idx]\n",
    "        y      = y[idx]\n",
    "        output,hidden = learn.model.forward(x,hidden)\n",
    "        loss += learn.loss_fn(output,y)                \n",
    "    if loss != 0 and learn.model.training:            \n",
    "        loss.backward()\n",
    "        learn.opt.step()\n",
    "        learn.opt.zero_grad()\n",
    "    return learn, hidden.detach(), loss\n",
    "\n",
    "def get_valid(learn,data):\n",
    "    learn.model.eval()\n",
    "    tot_loss = 0 \n",
    "    nb_it    = 0\n",
    "    with torch.no_grad():\n",
    "        for xb,yb in iter(data.valid_dl):    \n",
    "            if xb[0,0,1].item() == 1: hidden = learn.model.initHidden(xb.shape[0])            \n",
    "            learn, hidden, loss = one_rnn_batch(learn,xb,yb,hidden)  \n",
    "            tot_loss += loss/xb.size()[2]\n",
    "            nb_it    += 1\n",
    "        print(f\"\"\"getting validation\"\"\")\n",
    "    return tot_loss/nb_it\n",
    "\n",
    "def zero_idx(y):\n",
    "    idx = (y != 0).nonzero()\n",
    "    if idx.shape[0] < 2: return None\n",
    "    else: idx = idx.squeeze()\n",
    "    return idx\n",
    "\n",
    "def stats(i,valid_loss):\n",
    "    if i%100==0: \n",
    "        valid_loss.append(get_valid_loss(learn.model,data,Params,30,50))\n",
    "    if i%500==0: print(f\"\"\"checkpoint: {i} itterations done in {time.time() - start} seconds\"\"\")\n",
    "    i += 1   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting validation\n",
      "getting validation\n",
      "getting validation\n",
      "getting validation\n",
      "getting validation\n",
      "getting validation\n",
      "getting validation\n",
      "getting validation\n",
      "getting validation\n",
      "getting validation\n",
      "getting validation\n",
      "getting validation\n",
      "getting validation\n",
      "getting validation\n",
      "getting validation\n",
      "getting validation\n",
      "getting validation\n",
      "getting validation\n",
      "getting validation\n",
      "getting validation\n",
      "getting validation\n",
      "getting validation\n",
      "getting validation\n",
      "getting validation\n",
      "getting validation\n",
      "getting validation\n",
      "getting validation\n",
      "getting validation\n",
      "getting validation\n",
      "getting validation\n",
      "getting validation\n",
      "getting validation\n",
      "getting validation\n",
      "getting validation\n",
      "getting validation\n",
      "getting validation\n",
      "getting validation\n",
      "getting validation\n",
      "getting validation\n",
      "getting validation\n",
      "getting validation\n",
      "getting validation\n",
      "getting validation\n",
      "getting validation\n",
      "getting validation\n",
      "getting validation\n",
      "getting validation\n",
      "getting validation\n",
      "getting validation\n",
      "getting validation\n",
      "getting validation\n",
      "getting validation\n",
      "getting validation\n",
      "getting validation\n",
      "getting validation\n",
      "getting validation\n",
      "getting validation\n",
      "getting validation\n",
      "getting validation\n",
      "getting validation\n",
      "getting validation\n",
      "getting validation\n",
      "getting validation\n"
     ]
    }
   ],
   "source": [
    "sql   = 30\n",
    "bs    = 15\n",
    "lr    = 0.0005\n",
    "hd_sz = 150\n",
    "data       = pp_trumpdata(path+\"/data/trump/\", [0.9,0.95], bs)\n",
    "rnn = cuda(RNN(len(data.decoder), hd_sz, 1))\n",
    "learn = Learner(rnn,nn.NLLLoss(),data,lr)\n",
    "data.train_dl = iter(TweetDataLoader(data,data.train.tweets,bs,sql))\n",
    "data.valid_dl = TweetDataLoader(data,data.valid.tweets[0:60],bs,sql)\n",
    "learn, hidden, valid_loss = fit_rnn(1, learn, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f8c50d9d198>]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(valid_loss[0:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 349])\n",
      "torch.Size([1, 150])\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'Data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-b0a99eff528b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgenerate_seq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-17-5d377b65a804>\u001b[0m in \u001b[0;36mgenerate_seq\u001b[0;34m(model, data, sql, symbol)\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0mcum_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcumsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0midx\u001b[0m      \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcum_prob\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m             \u001b[0msymbol\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0mData\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m             \u001b[0mresult\u001b[0m  \u001b[0;34m+=\u001b[0m \u001b[0msymbol\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Data' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(learn, epochs, callbacks):\n",
    "    cb_handler = CallbackHandler(callbacks)\n",
    "    cb_handler.on_train_begin(epochs, learn)\n",
    "    for epoch in range(epochs):\n",
    "        learn.model.train()\n",
    "        cb_nalder.on_epoch_begin(epoch)\n",
    "        for xb, yb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs         = 15\n",
    "data       = pp_trumpdata(path+\"/data/trump/\", [0.9,0.95], bs)\n",
    "Params     = init_params(len(Data.encoder),bs)\n",
    "Params.sql = 30\n",
    "Params.bs  = 15\n",
    "data.train_dl = iter(TweetDataLoader(data.train.tweets[0:200],Params.bs,Params.sql))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### start coding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(plot_valid[1:-1])\n",
    "plt.show()\n",
    "print(plot_valid[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "# plt.plot(Plots.valid1[1:-1])\n",
    "plt.plot(Plots.valid2[1:-1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_parentbatch(tweets, bs, sql, symbol='¬£'):\n",
    "    f\"\"\"each parent-batch will have different numbers of sub-batches depending on how long the tweets are\"\"\"\n",
    "    assert(len(tweets)/bs*10%2==0)\n",
    "    bch_strs = batch_strings(tweets,bs,sql)\n",
    "    parent_batches = []\n",
    "    for pb in range(len(bch_strs)):\n",
    "        bch       = bch_strs[pb]\n",
    "        n_tweet   = bs\n",
    "        n_segment = math.ceil(len(bch[0])/sql)\n",
    "        sbx = torch.zeros(n_tweet,n_segment,sql,len(Data.decoder))\n",
    "        sby = torch.zeros(n_tweet,n_segment,sql).long()\n",
    "\n",
    "        for tweet in range(n_tweet):\n",
    "            if re.search(symbol,bch[tweet]): position = re.search(symbol,bch[tweet]).span()[0]\n",
    "            else:                            position = len(bch[tweet])\n",
    "            x_str = change_char(bch[tweet],position-1,symbol)\n",
    "            y_str = bch[tweet][1:len(bch[tweet])]+symbol                \n",
    "            for segment in range(n_segment):\n",
    "                x = x_str[sql*segment:sql*(segment+1)]\n",
    "                y = y_str[sql*segment:sql*(segment+1)]  \n",
    "                sbx[tweet,segment] = encodestr(x,Data.encoder)\n",
    "                sby[tweet,segment] = torch.Tensor([Data.encoder[char] for char in y])                \n",
    "                \n",
    "        sb_ds = SBDataLoader(sbx, sby)\n",
    "        parent_batches.append(sb_ds)\n",
    "    return parent_batches\n",
    "\n",
    "class ParentDataLoader():\n",
    "    def __init__(self, ds): \n",
    "        self.ds = ds\n",
    "    def __iter__(self):    \n",
    "        for i in range(len(self.ds)):\n",
    "            iterator = iter(self.ds[i])\n",
    "            yield next(iterator), True\n",
    "            try:\n",
    "                while True:                \n",
    "                    yield next(iterator), False \n",
    "            except StopIteration:\n",
    "                pass\n",
    "            \n",
    "def train_model(learner,Params,n_itter,plot_valid=None,hidden=None):\n",
    "#     optimizer = optim.Adam(model.parameters(), lr=Params.lr)\n",
    "    \n",
    "    start = time.time()\n",
    "    if learner.opt is None: learner.opt = optim.RMSprop(learner.model.parameters(), lr=Params.lr)\n",
    "    if plot_valid  is None: plot_valid  = []\n",
    "    if hidden      is None: hidden      = learner.model.initHidden(Params.bs)    \n",
    "        \n",
    "    for i in range(n_itter):\n",
    "        (X,Y), usezerostate     = next(data.train_dl)\n",
    "        if usezerostate: hidden = learner.model.initHidden(Params.bs)\n",
    "\n",
    "        loss = 0\n",
    "        for char in range(X.shape[1]):\n",
    "            x,y = X[:,char],Y[:,char]\n",
    "\n",
    "            idx = zero_idx(y)\n",
    "            if idx is None: break\n",
    "            hidden = hidden[idx]\n",
    "            x      = x[idx]\n",
    "            y      = y[idx]\n",
    "            \n",
    "            output,hidden = learner.model.forward(x,hidden)\n",
    "            loss += learner.loss_fn(output,y)\n",
    "        if loss != 0:\n",
    "            loss.backward()\n",
    "            learner.opt.step()\n",
    "            learner.opt.zero_grad()\n",
    "            hidden = hidden.detach()\n",
    "\n",
    "        if i%100==0: \n",
    "            plot_valid.append(get_valid_loss(learner.model,Data,Params,30,50))\n",
    "        if i%500==0: print(f\"\"\"checkpoint: {i} itterations done in {time.time() - start} seconds\"\"\")\n",
    "\n",
    "    print(f\"\"\"this training took {time.time()-start} seconds\"\"\")\n",
    "    return learner,plot_valid,hidden          \n",
    "\n",
    "def get_valid_loss(model,data,Params,seq_len,ntweet):\n",
    "    criterion = nn.NLLLoss()\n",
    "    start = time.time()\n",
    "    loss_valid = 0\n",
    "    hidden = cuda(torch.zeros(1,model.hd_sz))\n",
    "    with torch.no_grad():    \n",
    "        model.eval()\n",
    "        for t in range(ntweet):\n",
    "            tweet = data.valid.tweets[t]\n",
    "            xv, yv = generate_valid(data,tweet,seq_len)     \n",
    "            loss = 0\n",
    "            for char in range(xv.size()[1]):\n",
    "                x = xv[:,char,:].reshape(xv.shape[0],xv.shape[2])\n",
    "                output, hidden = model.forward(x,hidden)\n",
    "                y = yv[:,char,:]\n",
    "                loss += criterion(output,y.reshape(xv.shape[0]))\n",
    "            loss_valid += loss/(xv.size()[2])\n",
    "#     print(f\"calculating validation loss took {time.time()-start:.2f} seconds\")\n",
    "    del criterion\n",
    "    return loss_valid/ntweet\n",
    "\n",
    "def generate_valid(data, tweet, seq_len):\n",
    "    if seq_len > len(tweet)-1: seq_len = len(tweet)-1    \n",
    "    X = torch.zeros(1,seq_len,len(data.encoder))\n",
    "    Y = torch.zeros(1,seq_len,1)  \n",
    "    x = encodestr(tweet[0:seq_len],data.encoder)\n",
    "    y = torch.Tensor([data.encoder[char] for char in tweet[1:seq_len+1]])\n",
    "    X[0,:,:] = x.reshape(seq_len,len(data.encoder))\n",
    "    Y[0,:,:] = y.reshape(seq_len,1)\n",
    "    return cuda(X),cuda(Y.long())\n",
    "\n",
    "def init_params(in_sz, bs, hd_sz=150):\n",
    "    Params = Struct()\n",
    "    Params.ni      = 3000\n",
    "    Params.ne      = 1\n",
    "    Params.hd_sz   = hd_sz\n",
    "    Params.in_sz   = in_sz\n",
    "    Params.sql     = 10\n",
    "    Params.iv_pr   = 200\n",
    "    Params.iv_pl   = 100\n",
    "    Params.n_e     = 1\n",
    "    Params.n_i     = 1000\n",
    "    Params.use_opt = True \n",
    "    Params.lr      = 0.0005\n",
    "    Params.bs      = bs\n",
    "    return Params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### functions I should not need anymore"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
