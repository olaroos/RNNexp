{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import time\n",
    "import copy\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "# from torchviz import make_dot\n",
    "\n",
    "cuda_available = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if cuda_available else \"cpu\")\n",
    "print(f'''using device {device}''')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import numpy as np\n",
    "import pickle\n",
    "import random \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.OutputArea.auto_scroll_threshold = 9999;\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.auto_scroll_threshold = 9999;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def usecuda(input):\n",
    "    if torch.cuda.is_available(): return input.cuda()\n",
    "    return input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/r2/Documents/RNNexp\n"
     ]
    }
   ],
   "source": [
    "path = !pwd\n",
    "path = path[0]\n",
    "print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.read_pickle(path+\"/data/step3_DAT_MT_USDJPY_M1_2018_merged_pickled\") \n",
    "# data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Struct():\n",
    "    pass \n",
    "\n",
    "def load_trumpdata(datapath):\n",
    "    import json \n",
    "    tweets, tweet_str = [], ''\n",
    "    filenames = ['condensed_2018.json', 'condensed_2016.json', 'condensed_2017.json', 'condensed_2018.json']\n",
    "    for fname in filenames:\n",
    "        f = open(datapath+fname,\"r\")\n",
    "        data = f.readline()\n",
    "        f.close()\n",
    "        data_tr = json.loads(data)\n",
    "        for line in range(0,len(data_tr)):\n",
    "            tweet = '*' + data_tr[line][\"text\"].rstrip('\\\\') + 'â‚¬'\n",
    "            tweets.append(tweet)\n",
    "            tweet_str = tweet_str + tweet            \n",
    "    symbols = list(set(tweet_str))\n",
    "    decoder = {idx: symbols[idx] for idx in range(0,len(symbols))}\n",
    "    encoder = {symbols[idx]: idx for idx in range(0,len(symbols))}        \n",
    "    return tweets, tweet_str, decoder, encoder\n",
    "\n",
    "def pp_trumpdata(filename, prop, bsize=1):\n",
    "    Data, train, valid, test = Struct(), Struct(), Struct(), Struct()        \n",
    "    tweets, tweet_str, Data.decoder, Data.encoder = load_trumpdata(filename)    \n",
    "\n",
    "    train.tweets = tweets[0:round(prop[0]*len(tweets))]\n",
    "    train.tweet_str = tweet_str[0:round(prop[1]*len(tweet_str))]    \n",
    "    valid.tweets = tweets[round(prop[0]*len(tweets)):round(prop[1]*len(tweets))]\n",
    "    valid.tweet_str = tweet_str[round(prop[0]*len(tweet_str)):round(prop[1]*len(tweet_str))]    \n",
    "    test.tweets  = tweets[round(prop[1]*len(tweets)):-1]\n",
    "    test.tweet_str  = tweet_str[round(prop[1]*len(tweet_str)):-1]    \n",
    "\n",
    "    train.batch_str = []\n",
    "    stepsize = round(len(train.tweet_str)/bsize-1)\n",
    "    for i in range(0,bsize):\n",
    "        train.batch_str.append(train.tweet_str[i*stepsize:(i+1)*stepsize])\n",
    "    valid.batch_str = [valid.tweet_str]\n",
    "    \n",
    "    Data.train, Data.valid, Data.test, Data.bsize = train, valid, test, bsize\n",
    "    return Data\n",
    "\n",
    "\n",
    "#     for i in range(0,len(tweets),bs):\n",
    "        \n",
    "\n",
    "\n",
    "def onehencode(symbol, encoder):\n",
    "    x = torch.zeros(len(encoder),1)\n",
    "    x[encoder[symbol]] = 1.0\n",
    "    return usecuda(x.t())\n",
    "\n",
    "def encodestr(string, encoder, seq_len):\n",
    "    x = torch.zeros((seq_len,len(encoder)))\n",
    "    x[[idx for idx in range(0,seq_len)],[encoder[char] for char in string]] = 1\n",
    "    return usecuda(x.unsqueeze(1))\n",
    "\n",
    "def generate_seq(model, hidden, symbol, seq_len, m, seed):\n",
    "    with torch.no_grad():\n",
    "        result_str = symbol\n",
    "        for i in range(seq_len):\n",
    "            x = onehencode(symbol,encoder)\n",
    "            output, new_hidden = model.forward(x,hidden)\n",
    "        \n",
    "            hidden = new_hidden.detach()\n",
    "            prob = np.exp(output.detach().data.cpu().numpy())\n",
    "            cum_prob = np.cumsum(prob)\n",
    "\n",
    "            a = random.random()\n",
    "            idx = np.where(cum_prob - a > 0)[0][0]\n",
    "            symbol = decoder[idx]\n",
    "            result_str += symbol\n",
    "\n",
    "        return result_str\n",
    "    \n",
    "def save_checkpoint(state, filename='models/checkpoint.pth.tar'):\n",
    "    torch.save(state, filename)\n",
    "\n",
    "def load_checkpoint(filename='models/checkpoint.pth.tar'):\n",
    "    checkpoint = torch.load(filename)    \n",
    "    for item in iter(checkpoint):\n",
    "        print(item)\n",
    "    model = RNN(checkpoint['in_sz'],checkpoint['hd_sz'],checkpoint['out_sz'])\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    #     optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    epoch = checkpoint['epoch']\n",
    "    loss = checkpoint['loss']\n",
    "    return model, epoch, loss    \n",
    "\n",
    "def get_valid_loss(model,Data,Params,seq_len,ntweet):\n",
    "    start = time.time()\n",
    "    loss_valid = 0\n",
    "    hidden = usecuda(torch.zeros(1,model.hd_sz))\n",
    "    with torch.no_grad():    \n",
    "        model.eval()\n",
    "        for t in range(ntweet):\n",
    "            tweet = Data.valid.tweets[t]\n",
    "            xv, yv = generate_valid(Data,tweet,seq_len)     \n",
    "            loss = 0\n",
    "            for char in range(xv.size()[1]):\n",
    "                x = xv[:,char,:].reshape(xv.shape[0],xv.shape[2])\n",
    "                output, hidden = model.forward(x,hidden)\n",
    "                y = yv[:,char,:]\n",
    "                loss += criterion(output,y.reshape(xv.shape[0]))\n",
    "            loss_valid += loss/(xv.size()[2])\n",
    "    print(f\"calculating validation loss took {time.time()-start:.2f} seconds\")\n",
    "    return loss_valid/ntweet\n",
    "\n",
    "def parse_hidden(x,hidden,Data,symbol='*'):\n",
    "    # use .data to not break the connection to the graph     \n",
    "    for i in range(0,x.shape[0]):\n",
    "        if onehdecode(x[i,:],Data.decoder) == symbol:\n",
    "            hidden.data[i,:] = torch.zeros(1,hidden.shape[1])\n",
    "    return hidden\n",
    "\n",
    "def train_batch(model,X,Y,Data,hidden,lr,optimizer,use_opt,update_hidden):\n",
    "    model.train()\n",
    "    if use_opt: optimizer.zero_grad() \n",
    "    else: model.zero_grad()\n",
    "    loss = 0\n",
    "    for char in range(X.size()[1]):\n",
    "        x = X[:,char,:].reshape(X.shape[0],X.shape[2])\n",
    "        if update_hidden: hidden = parse_hidden(x,hidden,Data,symbol='*')        \n",
    "        output, hidden = model.forward(x,hidden)\n",
    "        y = Y[:,char,:]\n",
    "        loss += criterion(output,y.reshape(X.shape[0]))\n",
    "    loss.backward()\n",
    "    if use_opt: optimizer.step()\n",
    "    else:\n",
    "        for p in model.parameters(): p.data.add_(-lr, p.grad.data)\n",
    "    # hidden.detach() because we are done with training...\n",
    "    return loss/(X.size()[2]), hidden.detach()\n",
    "\n",
    "def generate_valid(Data, tweet, seq_len):\n",
    "    if seq_len > len(tweet)-1: seq_len = len(tweet)-1    \n",
    "    X = torch.zeros(1,seq_len,len(Data.encoder))\n",
    "    Y = torch.zeros(1,seq_len,1)  \n",
    "    x = encodestr(tweet[0:seq_len],Data.encoder,seq_len)\n",
    "    y = torch.Tensor([Data.encoder[char] for char in tweet[1:seq_len+1]])\n",
    "    X[0,:,:] = x.reshape(seq_len,len(Data.encoder))\n",
    "    Y[0,:,:] = y.reshape(seq_len,1)\n",
    "    return usecuda(X),usecuda(Y.long())\n",
    "\n",
    "def generate_batch(e, Data, seq_len, get_valid=False):\n",
    "    if get_valid: \n",
    "        batch_str, bsize = Data.valid.batch_str, 1        \n",
    "    else: batch_str, bsize = Data.train.batch_str, Data.bsize\n",
    "    X = torch.zeros(bsize,seq_len,len(Data.encoder))\n",
    "    Y = torch.zeros(bsize,seq_len,1)\n",
    "    for i in range(0,bsize):        \n",
    "        x = encodestr(batch_str[i][e:e+seq_len],Data.encoder,seq_len)\n",
    "        y = torch.Tensor([Data.encoder[char] for char in batch_str[i][e+1:e+seq_len+1]])\n",
    "        X[i,:,:] = x.reshape(seq_len,len(Data.encoder))\n",
    "        Y[i,:,:] = y.reshape(seq_len,1)\n",
    "    return usecuda(X),usecuda(Y.long())\n",
    "\n",
    "def do_training(model,Data,Params,optimizer,update_hidden,Plots=0):\n",
    "    if Plots==0:\n",
    "        Plots = Struct()\n",
    "        Plots.loss_train, Plots.loss_valid = [], []\n",
    "    start      = time.time()\n",
    "    loss_train = 0\n",
    "    hidden     = usecuda(torch.zeros(Params.bsize,model.hd_sz))\n",
    "    for epoch in range(Params.ne):\n",
    "        char_idx = 0\n",
    "        i = 0 \n",
    "        while i < Params.ni and char_idx < len(Data.train.batch_str[0])-Params.seq_len-1:\n",
    "            X,Y          = generate_batch(char_idx, Data, Params.seq_len,False)\n",
    "            loss, hidden = train_batch(model,X,Y,Data,hidden,Params.lr,optimizer,True,update_hidden)\n",
    "            loss_train  += loss         \n",
    "            if i%Params.iv_pl  == 0:  \n",
    "                Plots.loss_valid.append(get_valid_loss(model,Data,Params,30,50))\n",
    "                print(Plots.loss_valid[-1])\n",
    "                Plots.loss_train.append(loss_train/Params.iv_pl)\n",
    "                loss_train = 0 \n",
    "            char_idx += Params.seq_len + 1\n",
    "            i        += 1\n",
    "        print(f\"\"\"\\n epoch {epoch+1} took {time.time() - start:.2f} seconds\"\"\")  \n",
    "    return Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## my RNN module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNN,self).__init__()\n",
    "        self.hd_sz  = hidden_size\n",
    "        self.in_sz  = input_size\n",
    "        self.out_sz = output_size\n",
    "        \n",
    "        self.h1 = nn.Linear(input_size + hidden_size, hidden_size)        \n",
    "        self.o1 = nn.Linear(input_size + hidden_size, input_size)\n",
    "        \n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "        \n",
    "    def forward(self, input, hidden):\n",
    "        combined = torch.cat((input, hidden), 1)\n",
    "        hidden = torch.tanh(self.h1(combined))\n",
    "        output = self.o1(combined)\n",
    "        output = self.softmax(output)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(hidden_layers[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = pp_trumpdata(path+\"/data/trump/\", [0.9,0.95], 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "Params = Struct()\n",
    "Params.hd_sz   = 150\n",
    "Params.in_sz   = len(Data.encoder)\n",
    "Params.seq_len = 30\n",
    "Params.iv_pr   = 200\n",
    "Params.iv_pl   = 100\n",
    "Params.ne      = 1\n",
    "Params.ni      = 1000\n",
    "Params.use_opt = True \n",
    "Params.lr      = 0.0005\n",
    "Params.bsize   = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.nn??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(self, y_hat, y, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad(str_list,token='%'):\n",
    "    max_len = len((max(str_list, key=len)))\n",
    "    for idx, row in enumerate(str_list):        \n",
    "        str_list[idx] = row + token*(max_len-len(row))\n",
    "    return str_list\n",
    "\n",
    "def setup_batches(tweets,bs):\n",
    "    bch_strs = [] \n",
    "    for i in range(round(len(tweets)/bs)-1):\n",
    "        bch_strs.append(pad(tweets[i*bs:(i+1)*bs]))\n",
    "    return bch_strs\n",
    "\n",
    "# if get_valid: \n",
    "#         batch_str, bsize = Data.valid.batch_str, 1        \n",
    "#     else: batch_str, bsize = Data.train.batch_str, Data.bsize\n",
    "#     X = torch.zeros(bsize,seq_len,len(Data.encoder))\n",
    "#     Y = torch.zeros(bsize,seq_len,1)\n",
    "#     for i in range(0,bsize):        \n",
    "#         x = encodestr(batch_str[i][e:e+seq_len],Data.encoder,seq_len)\n",
    "#         y = torch.Tensor([Data.encoder[char] for char in batch_str[i][e+1:e+seq_len+1]])\n",
    "#         X[i,:,:] = x.reshape(seq_len,len(Data.encoder))\n",
    "#         Y[i,:,:] = y.reshape(seq_len,1)\n",
    "#     return usecuda(X),usecuda(Y.long())\n",
    "\n",
    "def get_xy(b_str, sql, bs):\n",
    "    X,Y = torch.zeros(bs,sql,len(Data.encoder)),torch.zeros(bs,sql,1)\n",
    "    for b in range(bs):\n",
    "        for i in range(0,len(b_str[b]),sql):\n",
    "            if i+sql > len(b_str[b])-1:\n",
    "                x_str, y_str = b_str[b][i:-1], b_str[b][i+1:len(b_str[b])]        \n",
    "            else:            \n",
    "                x_str, y_str = b_str[b][i:i+sql], b_str[b][i+1:i+1+sql]                \n",
    "\n",
    "            x = encodestr(x_str,Data.encoder,len(x_str))\n",
    "            y = torch.Tensor([Data.encoder[char] for char in y_str])\n",
    "    \n",
    "\n",
    "# def other(data):\n",
    "    \n",
    "\n",
    "# def something(bch_strs, sql):\n",
    "#     for batch in len(bch_strs)\n",
    "#         for data in batch:\n",
    "#             x,y = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "hejh ejhe\n",
      "4\n",
      "ejhe jhej\n",
      "8\n",
      "jhej hejh\n",
      "12\n",
      "he ej\n"
     ]
    }
   ],
   "source": [
    "get_xy(['hejhejhejhejhej'],4,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hej'"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_str = ['hejhejhejhejhej']\n",
    "b_str[0][12:110]\n",
    "# b_str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'string_to_xy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-198-a5b6ffe7474f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstring_to_xy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'string_to_xy' is not defined"
     ]
    }
   ],
   "source": [
    "bch_strs = setup_batches(Data1.train.tweets,bs=3)\n",
    "# now they are the same length\n",
    "sql = 6\n",
    "\n",
    "print(len(ds[0]))\n",
    "x,y = string_to_xy(ds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Dataset():\n",
    "    def __init__(self, x, y): self.x,self.y = x,y\n",
    "    def __len__(self): return len(self.x)\n",
    "    def __getitem__(self, i): return self.x[i],self.y[i]\n",
    "\n",
    "def get_dls(train_ds, valid_ds, tbs, vbs, **kwargs):\n",
    "    return (DataLoader(train_ds, batch_size=tbs, **kwargs),\n",
    "            DataLoader(valid_ds, batch_size=vbs, **kwargs))\n",
    "\n",
    "\n",
    "class DataLoader():\n",
    "    def __init__(self, ds, bs): self.ds, self.bs = ds,bs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating validation loss took 0.31 seconds\n",
      "tensor(0.5009, device='cuda:0')\n",
      "calculating validation loss took 0.31 seconds\n",
      "tensor(0.3001, device='cuda:0')\n",
      "calculating validation loss took 0.31 seconds\n",
      "tensor(0.2965, device='cuda:0')\n",
      "calculating validation loss took 0.31 seconds\n",
      "tensor(0.2922, device='cuda:0')\n",
      "calculating validation loss took 0.31 seconds\n",
      "tensor(0.2873, device='cuda:0')\n",
      "calculating validation loss took 0.31 seconds\n",
      "tensor(0.2848, device='cuda:0')\n",
      "calculating validation loss took 0.31 seconds\n",
      "tensor(0.2778, device='cuda:0')\n",
      "calculating validation loss took 0.31 seconds\n",
      "tensor(0.2730, device='cuda:0')\n",
      "calculating validation loss took 0.31 seconds\n",
      "tensor(0.2690, device='cuda:0')\n",
      "calculating validation loss took 0.31 seconds\n",
      "tensor(0.2649, device='cuda:0')\n",
      "\n",
      " epoch 1 took 21.58 seconds\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(24)\n",
    "rnn1 = usecuda(RNN(Params.in_sz, Params.hd_sz, 1))\n",
    "torch.manual_seed(24)\n",
    "rnn2 = usecuda(RNN(Params.in_sz, Params.hd_sz, 1))\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "optimizer1 = optim.RMSprop(rnn1.parameters(), lr=Params.lr)\n",
    "optimizer2 = optim.RMSprop(rnn2.parameters(), lr=Params.lr)\n",
    "\n",
    "Params1 = copy.deepcopy(Params)\n",
    "Params2 = copy.deepcopy(Params)\n",
    "Params1.bsize = 10\n",
    "Params2.bsize = 10\n",
    "\n",
    "Data1 = pp_trumpdata(path+\"/data/trump/\", [0.9,0.95], Params1.bsize)\n",
    "Data2 = pp_trumpdata(path+\"/data/trump/\", [0.9,0.95], Params2.bsize)\n",
    "\n",
    "# Plots1 = do_training(rnn1,Data1,Params1,optimizer1,True)\n",
    "Plots2 = do_training(rnn2,Data2,Params2,optimizer2,False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculating validation loss took 0.32 seconds\n",
    "tensor(0.5019, device='cuda:0')\n",
    "calculating validation loss took 0.32 seconds\n",
    "tensor(0.2999, device='cuda:0')\n",
    "calculating validation loss took 0.32 seconds\n",
    "tensor(0.2962, device='cuda:0')\n",
    "calculating validation loss took 0.33 seconds\n",
    "tensor(0.2914, device='cuda:0')\n",
    "calculating validation loss took 0.32 seconds\n",
    "tensor(0.2868, device='cuda:0')\n",
    "calculating validation loss took 0.32 seconds\n",
    "tensor(0.2834, device='cuda:0')\n",
    "calculating validation loss took 0.32 seconds\n",
    "tensor(0.2763, device='cuda:0')\n",
    "calculating validation loss took 0.32 seconds\n",
    "tensor(0.2716, device='cuda:0')\n",
    "calculating validation loss took 0.32 seconds\n",
    "tensor(0.2678, device='cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(Plots1.loss_valid[1:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(Plots2.loss_valid[1:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,Y = generate_batch(15, Data2, Params.seq_len)\n",
    "\n",
    "\n",
    "hidden = torch.ones(10,150).cuda()\n",
    "target = onehencode('t',Data2.encoder)\n",
    "\n",
    "def parse_hidden(x, hidden,Data,symbol='*'):\n",
    "    new_hidden = copy.deepcopy(hidden.detach())\n",
    "    for i in range(0,x.shape[0]):\n",
    "        if onehdecode(x[i,:],Data.decoder) == symbol:\n",
    "            new_hidden[i,:] = torch.zeros(1,hidden.shape[1])\n",
    "    return new_hidden\n",
    "\n",
    "new_hidden = parse_hidden(X[:,4,:],hidden,Data2, symbol='t')\n",
    "            \n",
    "            \n",
    "# new_hidden = copy.deepcopy(x[:,0,:].detach())\n",
    "# new_hidden = torch.zeros(10,347).cuda()\n",
    "# for i in range(0,Params2.bsize):\n",
    "#     val, idx = torch.max(x[i,0,:],0)\n",
    "#     print(Data2.decoder[idx.item()])\n",
    "#     if Data2.decoder[idx.item()] == 't':\n",
    "#         new_hidden[i,:] = torch.zeros(1,347).cuda()\n",
    "        \n",
    "\n",
    "#         new_hidden[idx] = x[idx,0,:]\n",
    "\n",
    "#     target = np.array(onehencode('t',Data2.encoder).cpu())\n",
    "# x2 = np.array(x.cpu())\n",
    "# torch.ones(10,347).cuda()\n",
    "\n",
    "# print(np.where(x2[:,0,:] == target, 0, 1))\n",
    "\n",
    "# np.array(target)\n",
    "\n",
    "# new_hidden = torch.where(x[0:5,0,:] == target, torch.zeros(1,347).cuda() ,torch.ones(1,347).cuda())\n",
    "# print(new_hidden.shape)\n",
    "# print(new_hidden[:,0:5])\n",
    "\n",
    "# new_hidden = torch.repeat(new_hidden[0,:])\n",
    "# new_hidden = torch.mul(hidden, new_hidden)\n",
    "\n",
    "for idx in range(0,len(new_hidden)):\n",
    "    print(onehdecode(x[idx,4,:],Data2.decoder))\n",
    "    print(str(new_hidden[idx,0:10])+'\\n------------')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehdecode(vector, decoder):\n",
    "    val, idx = torch.max(vector,0)\n",
    "    return decoder[idx.item()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = generate_batch(15, Data2, Params.seq_len)\n",
    "# print(torch.where(x[0][0][:] == onehencode('*',Data2.encoder)))\n",
    "# print(x[0][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_checkpoint({\n",
    "            'epoch': epoch,\n",
    "            'arch': \"1_RNN\",\n",
    "            'state_dict': rnn.state_dict(),\n",
    "            'hd_sz': rnn.hd_sz,\n",
    "            'in_sz': rnn.in_sz,\n",
    "            'out_sz': rnn.out_sz,\n",
    "            'loss': loss,\n",
    "            'best_prec1': None,\n",
    "            'optimizer' : None,\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn2, epoch, loss = load_checkpoint(filename='models/checkpoint.pth.tar')\n",
    "rnn2.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(generate_seq(rnn2, torch.zeros(1,hsize).cuda(),'T',100,m,42))\n",
    "print(generate_seq(rnn, torch.zeros(1,hsize).cuda(),'T',100,m,42))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### build RNN network with LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### cut input into seq length bits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[['Open','High','Low','Close']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff = 0.2\n",
    "set_train = data[0:round(len(data)*cutoff)]\n",
    "set_test  = data[round(len(data)*cutoff):-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sz = set_train.shape[1]\n",
    "hidden_sz = 100\n",
    "output_sz = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = RNN(input_sz, hidden_sz, output_sz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for index, row in set_train.iterrows():\n",
    "#     print(np.array(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.005\n",
    "\n",
    "def train(X,Y)\n",
    "    hidden = rnn.initHidden()\n",
    "    \n",
    "    rnn.zero_grad()\n",
    "    \n",
    "    for i in range(X.size()[0]):\n",
    "        output, hidden = rnn(X[i], hidden)\n",
    "        \n",
    "    loss = criterion(output, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
