{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device cuda:0\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import time\n",
    "import copy\n",
    "import math \n",
    "import re\n",
    "import json \n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "import pickle\n",
    "import random \n",
    "import pandas as pd\n",
    "\n",
    "cuda_available = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if cuda_available else \"cpu\")\n",
    "print(f'''using device {device}''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.OutputArea.auto_scroll_threshold = 9999;\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.auto_scroll_threshold = 9999;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cuda(input):\n",
    "    if torch.cuda.is_available(): return input.cuda()\n",
    "    return input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/r2/Documents/RNNexp\n"
     ]
    }
   ],
   "source": [
    "path = !pwd\n",
    "path = path[0]\n",
    "print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.read_pickle(path+\"/data/step3_DAT_MT_USDJPY_M1_2018_merged_pickled\") \n",
    "# data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/r2/Documents/RNNexp'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f = open(datapath,\"r\")\n",
    "# data = f.readline()\n",
    "# f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Struct():\n",
    "    pass \n",
    "\n",
    "def load_trumpdata(datapath, pad_tok='£', start_tok='^', end_tok='€'):\n",
    "    print('wtf')\n",
    "    van_tws, tws, van_tw_str, tw_str = [],[],'',''\n",
    "    filenames = ['condensed_2018.json', 'condensed_2016.json', 'condensed_2017.json', 'condensed_2018.json']\n",
    "    for fname in filenames:\n",
    "        f = open(datapath+fname,\"r\")\n",
    "        data = f.readline()\n",
    "        f.close()\n",
    "        data_tr = json.loads(data)\n",
    "        for line in range(0,len(data_tr)):\n",
    "            tweet      = data_tr[line][\"text\"].rstrip('\\\\')\n",
    "\n",
    "            van_tw_str = van_tw_str + tweet \n",
    "            van_tws.append(tweet)    \n",
    "#     print(''.join(OrderedDict.fromkeys(van_tws).keys())       \n",
    "#     print(set(van_tw_str))\n",
    "#     print(van_tw_str[0:40])\n",
    "#     print(tweet)\n",
    "    symbols = list(set(van_tw_str))  \n",
    "#     print(symbols)\n",
    "    assert(pad_tok   not in symbols)\n",
    "    assert(start_tok not in symbols)\n",
    "    assert(end_tok   not in symbols)\n",
    "\n",
    "    for tweet in van_tws:\n",
    "        pad_tweet = start_tok + tweet + end_tok\n",
    "        tw_str    = tw_str + pad_tweet            \n",
    "        tws.append(pad_tweet)        \n",
    "    symbols = [pad_tok, start_tok] + symbols + [end_tok]   \n",
    "    decoder = {idx: symbols[idx] for idx in range(0,len(symbols))}\n",
    "    encoder = {symbols[idx]: idx for idx in range(0,len(symbols))}        \n",
    "#     print(decoder)\n",
    "    return tws, tw_str, decoder, encoder\n",
    "\n",
    "def pp_trumpdata(filename, prop, bsize=1):\n",
    "    data, train, valid, test = Struct(), Struct(), Struct(), Struct()        \n",
    "    tweets, tweet_str, data.decoder, data.encoder = load_trumpdata(filename)    \n",
    "\n",
    "    train.tweets = tweets[0:round(prop[0]*len(tweets))]\n",
    "    train.tweet_str = tweet_str[0:round(prop[1]*len(tweet_str))]    \n",
    "    valid.tweets = tweets[round(prop[0]*len(tweets)):round(prop[1]*len(tweets))]\n",
    "    valid.tweet_str = tweet_str[round(prop[0]*len(tweet_str)):round(prop[1]*len(tweet_str))]    \n",
    "    test.tweets  = tweets[round(prop[1]*len(tweets)):-1]\n",
    "    test.tweet_str  = tweet_str[round(prop[1]*len(tweet_str)):-1]    \n",
    "\n",
    "    train.batch_str = []\n",
    "    stepsize = round(len(train.tweet_str)/bsize-1)\n",
    "    for i in range(0,bsize):\n",
    "        train.batch_str.append(train.tweet_str[i*stepsize:(i+1)*stepsize])\n",
    "    valid.batch_str = [valid.tweet_str]\n",
    "    \n",
    "    data.train, data.valid, data.test, data.bsize = train, valid, test, bsize\n",
    "    return data\n",
    "\n",
    "def save_checkpoint(state, filename='models/checkpoint.pth.tar'):\n",
    "    torch.save(state, filename)\n",
    "\n",
    "def load_checkpoint(filename='models/checkpoint.pth.tar'):\n",
    "    checkpoint = torch.load(filename)    \n",
    "    for item in iter(checkpoint):\n",
    "        print(item)\n",
    "    model = RNN(checkpoint['in_sz'],checkpoint['hd_sz'],checkpoint['out_sz'])\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    #     optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    epoch = checkpoint['epoch']\n",
    "    loss = checkpoint['loss']\n",
    "    return model, epoch, loss    \n",
    "\n",
    "def get_valid_loss(model,data,sql,ntweet):\n",
    "    criterion = nn.NLLLoss()\n",
    "    start = time.time()\n",
    "    loss_valid = 0\n",
    "    hidden = cuda(torch.zeros(1,model.hd_sz))\n",
    "    with torch.no_grad():    \n",
    "        model.eval()\n",
    "        for t in range(ntweet):\n",
    "            tweet = data.valid.tweets[t]\n",
    "            xv, yv = generate_valid(data,tweet,sql)     \n",
    "            loss = 0\n",
    "            for char in range(xv.size()[1]):\n",
    "                x = xv[:,char,:].reshape(xv.shape[0],xv.shape[2])\n",
    "                output, hidden = model.forward(x,hidden)\n",
    "                y = yv[:,char,:]\n",
    "                loss += criterion(output,y.reshape(xv.shape[0]))              \n",
    "            loss_valid += loss/(xv.size()[2])\n",
    "#     print(f\"calculating validation loss took {time.time()-start:.2f} seconds\")\n",
    "    model.train()\n",
    "    del criterion\n",
    "    return loss_valid/ntweet\n",
    "\n",
    "def generate_valid(data, tweet, seq_len):\n",
    "    if seq_len > len(tweet)-1: seq_len = len(tweet)-1    \n",
    "    X = torch.zeros(1,seq_len,len(data.encoder))\n",
    "    Y = torch.zeros(1,seq_len,1)  \n",
    "    x = encodestr(tweet[0:seq_len],data.encoder)\n",
    "    y = torch.Tensor([data.encoder[char] for char in tweet[1:seq_len+1]])\n",
    "    X[0,:,:] = x.reshape(seq_len,len(data.encoder))\n",
    "    Y[0,:,:] = y.reshape(seq_len,1)\n",
    "    return cuda(X),cuda(Y.long())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### encoder/decoders "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encodestr(string, encoder):\n",
    "    x = torch.zeros((len(string),len(encoder)))\n",
    "    x[[idx for idx in range(0,len(string))],[encoder[char] for char in string]] = 1\n",
    "    return x\n",
    "\n",
    "def onehencode(symbol, encoder):\n",
    "    x = torch.zeros(len(encoder),1)\n",
    "    x[encoder[symbol]] = 1.0\n",
    "    return x.t()\n",
    "\n",
    "def encode(string, encoder):\n",
    "    return torch.Tensor([encoder[char] for char in y_str])\n",
    "\n",
    "def onehdecode(X,decoder):\n",
    "    string = ''\n",
    "    for char in range(X.shape[0]):\n",
    "        val, idx = torch.max(X[char],0)\n",
    "        string += decoder[idx.item()]\n",
    "    print(string)\n",
    "    \n",
    "def ydecode(Y,decoder):\n",
    "    string = ''\n",
    "    for char in range(Y.shape[0]): string += decoder[Y[char].item()]\n",
    "    print(string)\n",
    "\n",
    "def change_char(s, p, r):\n",
    "    return s[:p]+r+s[p+1:] \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## my RNN module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNoriginal(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNNoriginal,self).__init__()\n",
    "        self.hd_sz  = hidden_size\n",
    "        self.in_sz  = input_size\n",
    "        self.out_sz = output_size\n",
    "        \n",
    "        self.h1  = nn.Linear(input_size + hidden_size, hidden_size)               \n",
    "        self.o1   = nn.Linear(input_size + hidden_size, input_size)\n",
    "\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "        \n",
    "    def forward(self, input, hidden):\n",
    "        combined = torch.cat((input, hidden), 1)    \n",
    "        \n",
    "        hidden   = self.h1(combined)\n",
    "        hidden   = torch.tanh(hidden)\n",
    "        \n",
    "        output   = self.o1(combined)\n",
    "        output   = self.softmax(output)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self,bs):\n",
    "        return cuda(torch.zeros(bs,self.hd_sz))\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNN,self).__init__()\n",
    "        self.hd_sz  = hidden_size\n",
    "        self.in_sz  = input_size\n",
    "        self.out_sz = output_size\n",
    "        \n",
    "        combined = input_size+hidden_size\n",
    "        \n",
    "        self.h1      = nn.Linear(combined, hidden_size)               \n",
    "\n",
    "        self.o1      = nn.Linear(combined, combined)\n",
    "        self.bn1     = nn.BatchNorm1d(combined)\n",
    "        self.relu    = nn.ReLU(combined)\n",
    "\n",
    "        self.o2      = nn.Linear(combined, input_size)\n",
    "        self.bn2     = nn.BatchNorm1d(input_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "        \n",
    "    def forward(self, input, hidden):\n",
    "        combined = torch.cat((input, hidden), 1)    \n",
    "        \n",
    "        hidden   = self.h1(combined)\n",
    "        hidden   = torch.tanh(hidden)\n",
    "        \n",
    "        output   = self.o1(combined)\n",
    "        output   = self.bn1(output)\n",
    "        output   = self.relu(output)\n",
    "        \n",
    "        output   = self.o2(output)\n",
    "        output   = self.bn2(output)\n",
    "        output   = self.softmax(output)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self,bs):\n",
    "        return cuda(torch.zeros(bs,self.hd_sz))\n",
    "\n",
    "def weights_init_uniform(m):\n",
    "    classname = m.__class__.__name__\n",
    "    # for every Linear layer in a model..\n",
    "    if classname.find('Linear') != -1:\n",
    "        # apply a uniform distribution to the weights and a bias=0\n",
    "        m.weight.data.uniform_(0.0, 1.0)\n",
    "        m.bias.data.fill_(0)\n",
    "\n",
    "def weights_init_xavier(m):\n",
    "    classname = m.__class__.__name__\n",
    "    # for every Linear layer in a model..\n",
    "    if classname.find('Linear') != -1:\n",
    "        torch.nn.init.xavier_uniform_(m.weight)\n",
    "        m.bias.data.fill_(0.01)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataLoaders, Itterators, DataSets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad(str_list,sql=1,token='£'):\n",
    "    f\"\"\"pad all strings in a list to max_len\"\"\"\n",
    "    max_len = math.ceil(len(max(str_list, key=len))/sql)*sql\n",
    "    for idx, row in enumerate(str_list):        \n",
    "        str_list[idx] = row + token*(max_len-len(row))\n",
    "    if len(str_list) == 1: return str_list[0]\n",
    "    return str_list\n",
    "\n",
    "def mk_tweetbatch(data,tweets,bs,sql,symbol='£'):\n",
    "    assert(math.floor(len(tweets)/bs)==len(tweets)/bs)\n",
    "    bch       = batch_strings(tweets,bs,sql)[0]\n",
    "    assert(math.floor(len(bch[0])/sql)==len(bch[0])/sql)         \n",
    "    n_segment = int(len(bch[0])/sql)\n",
    "    sbx       = torch.zeros(bs,n_segment,sql,len(data.decoder))\n",
    "    sby       = torch.zeros(bs,n_segment,sql).long()\n",
    "    for tweet in range(bs):\n",
    "        \"\"\"for target we don't use first char, compensate with one padded char\"\"\"\n",
    "        y_str = bch[tweet][1:len(bch[tweet])]+symbol      \n",
    "        \n",
    "        chng_pos = len(bch[tweet])\n",
    "        \"\"\"if we find padded char, we know that tweet ended, remove last char of tweet\"\"\"        \n",
    "        if re.search(symbol,bch[tweet]): chng_pos = re.search(symbol,bch[tweet]).span()[0]       \n",
    "        x_str = change_char(bch[tweet],chng_pos-1,symbol)     \n",
    "        \n",
    "        for segment in range(n_segment):\n",
    "            x = x_str[sql*segment:sql*(segment+1)]\n",
    "            y = y_str[sql*segment:sql*(segment+1)]  \n",
    "            sbx[tweet,segment] = encodestr(x,data.encoder)\n",
    "            sby[tweet,segment] = torch.Tensor([data.encoder[char] for char in y])                    \n",
    "    return sbx,sby\n",
    "\n",
    "class TweetDataLoader():\n",
    "    def __init__(self,data,tweets, bs, sql):    \n",
    "        assert(math.floor(len(tweets)/bs)==len(tweets)/bs)\n",
    "        self.data   = data\n",
    "        self.tweets = tweets\n",
    "        self.bs     = bs         \n",
    "        self.sql    = sql\n",
    "        random.shuffle(self.tweets)\n",
    "\n",
    "    def __iter__(self):  \n",
    "        i=-1\n",
    "        while True:\n",
    "            i+=1\n",
    "            twt = self.tweets[i*self.bs:(i+1)*self.bs]\n",
    "            sbx,sby = mk_tweetbatch(self.data,twt,self.bs,self.sql)\n",
    "            sbloader = iter(SBDataLoader(sbx,sby))            \n",
    "            yield next(sbloader), True\n",
    "            try:\n",
    "                while True:                \n",
    "                    yield next(sbloader), False \n",
    "            except StopIteration:\n",
    "                pass            \n",
    "            if i==round(len(self.tweets)/self.bs)-1:\n",
    "                random.shuffle(self.tweets)\n",
    "                i=-1\n",
    "\n",
    "class SBDataLoader():\n",
    "    def __init__(self, sbx, sby): \n",
    "        self.sbx, self.sby = sbx, sby\n",
    "    def __iter__(self):\n",
    "        for j in range(self.sbx.shape[1]): yield cuda(self.sbx[:,j]), cuda(self.sby[:,j])\n",
    "\n",
    "def train_model(learner,data,n_itter,lr,bs,plot_valid=None,hidden=None):\n",
    "#     optimizer = optim.Adam(model.parameters(), lr=Params.lr)\n",
    "    \n",
    "    start = time.time()\n",
    "    if learner.opt is None: learner.opt = optim.RMSprop(learner.model.parameters(), lr=lr)\n",
    "    if plot_valid  is None: plot_valid  = []\n",
    "    if hidden      is None: hidden      = learner.model.initHidden(bs)    \n",
    "        \n",
    "    for i in range(n_itter):\n",
    "        (X,Y), usezerostate     = next(data.train_dl)\n",
    "        if usezerostate: hidden = learner.model.initHidden(bs)\n",
    "\n",
    "        loss = 0\n",
    "        for char in range(X.shape[1]):\n",
    "            x,y = X[:,char],Y[:,char]\n",
    "\n",
    "            f\"\"\"remove padded characters\"\"\"\n",
    "            idx = (y != 0).nonzero()\n",
    "            if idx.shape[0] < 2: break\n",
    "#             if idx.shape[0] == 1: idx = idx.squeeze(0)\n",
    "            else:                 idx = idx.squeeze()                \n",
    "            hidden = hidden[idx]\n",
    "            x = x[idx]\n",
    "            y = y[idx]\n",
    "\n",
    "            \n",
    "            output,hidden = learner.model.forward(x,hidden)\n",
    "            loss += learner.loss_fn(output,y)\n",
    "        if loss != 0:\n",
    "            loss.backward()\n",
    "            learner.opt.step()\n",
    "            learner.opt.zero_grad()\n",
    "            hidden = hidden.detach()\n",
    "\n",
    "        if i%100==0: \n",
    "#             pass\n",
    "            plot_valid.append(get_valid_loss(learner.model,data,30,50))\n",
    "#             plot_valid.append(get_validation(learner,data,4))\n",
    "#             generate_seq(learner.model,data,200)    \n",
    "#             learner.model.train()\n",
    "        if i%500==0: print(f\"\"\"checkpoint: {i} itterations done in {time.time() - start} seconds\"\"\")\n",
    "\n",
    "    print(f\"\"\"this training took {time.time()-start} seconds\"\"\")\n",
    "    return learner,plot_valid,hidden\n",
    "\n",
    "def batch_strings(tweets,bs,sql=1):\n",
    "    f\"\"\"creates a list of batchsize-list of strings of same length and sort each batch with longest string first.\"\"\"    \n",
    "    \"\"\"NOT SURE ABOUT THIS OFFSET, BUT THE PREVIOUS CODE ALWAYS MADE A 0\"\"\"\n",
    "    offset = -1*((len(tweets)/bs)*10%2!=0)    \n",
    "#     offset = -1*((math.floor(len(tweets)/bs)==len(tweets)/bs)==0)    \n",
    "    bch_strs = [] \n",
    "    for i in range(round(len(tweets)/bs)+offset):\n",
    "        strings = tweets[i*bs:(i+1)*bs]\n",
    "        strings.sort(key=len,reverse=True)\n",
    "        pad_strings = pad(strings,sql)\n",
    "        bch_strs.append(pad_strings)\n",
    "    return bch_strs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### building FastAI classes to be used with callbacks in future\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Learner():\n",
    "    def __init__(self, model, opt, loss_fn, data):\n",
    "        self.model,self.opt,self.loss_fn,self.data = model,opt,loss_fn,data\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_valid_loss_copy(model,data,sql,ntweet):\n",
    "    criterion = nn.NLLLoss()\n",
    "    start = time.time()\n",
    "    loss_valid = 0\n",
    "    hidden = cuda(torch.zeros(1,model.hd_sz))\n",
    "    with torch.no_grad():    \n",
    "        model.eval()\n",
    "        for t in range(ntweet):\n",
    "            tweet = data.valid.tweets[t]\n",
    "            xv, yv = generate_valid(data,tweet,sql)     \n",
    "            loss = 0\n",
    "            for char in range(xv.size()[1]):\n",
    "                x = xv[:,char,:].reshape(xv.shape[0],xv.shape[2])\n",
    "                output, hidden = model.forward(x,hidden)\n",
    "                y = yv[:,char,:]\n",
    "                loss += criterion(output,y.reshape(xv.shape[0]))\n",
    "            print(xv.size()[2])\n",
    "            loss_valid += loss/(xv.size()[2])\n",
    "#     print(f\"calculating validation loss took {time.time()-start:.2f} seconds\")\n",
    "    del criterion\n",
    "    return loss_valid/ntweet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### write new validation dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rnn_forward_batch(learn,hidden,xb,yb):\n",
    "\n",
    "    loss = 0        \n",
    "    for char in range(xb.shape[1]):\n",
    "        x,y = xb[:,char],yb[:,char]\n",
    "        \n",
    "        f\"\"\"remove padded characters\"\"\"\n",
    "        idx = (y != 0).nonzero()\n",
    "        if idx.shape[0] == 0: break\n",
    "        if idx.shape[0] == 1: idx = idx.squeeze(0)\n",
    "        else:                 idx = idx.squeeze()\n",
    "            \n",
    "        hidden = hidden[idx]\n",
    "        x = x[idx]\n",
    "        y = y[idx]\n",
    "#         print(x.shape)\n",
    "#         print(hidden.shape)\n",
    "        output,hidden = learn.model.forward(x,hidden)       \n",
    "        loss   += learn.loss_fn(output,y)\n",
    "    return learn,loss,hidden.detach()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_validation(learn,data,nb_iter):\n",
    "    print('running get_validation')\n",
    "    loss_valid = 0\n",
    "    learn.model.eval()    \n",
    "    with torch.no_grad():\n",
    "        valid_gen = iter(data.valid_dl)\n",
    "        for i in range(nb_iter):\n",
    "            (xb,yb), _ = next(valid_gen)   \n",
    "            if xb[0,0,1].item() == 1: hidden = learn.model.initHidden(15)                        \n",
    "            learn,loss,hidden = rnn_forward_batch(learn,hidden,xb,yb)            \n",
    "            loss_valid += loss/349       \n",
    "    learn.model.train()\n",
    "    return loss_valid/(nb_iter*bs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### start coding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def goterror(list_to_test):\n",
    "    alfabet = 'abcdefghijklmnopqrstuvxyz'\n",
    "    for char in alfabet:\n",
    "        if not char in list_to_test:\n",
    "            print(\"fail\")\n",
    "            raise AssertionError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wtf\n"
     ]
    }
   ],
   "source": [
    "sql = 30\n",
    "bs  = 15\n",
    "lr  = 0.0005 \n",
    "data       = pp_trumpdata(path+\"/data/trump/\", [0.9,0.95], bs)\n",
    "\n",
    "# dataloader = iter(TweetDataLoader(Data.train.tweets,Params.bs,Params.sql))\n",
    "data.valid_dl = TweetDataLoader(data,data.valid.tweets[0:300],bs,sql)\n",
    "data.train_dl = iter(TweetDataLoader(data,data.train.tweets,bs,sql))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_list = [val for idx,val in data.decoder.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "goterror(a_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint: 0 itterations done in 0.5474038124084473 seconds\n",
      "this training took 18.501032829284668 seconds\n"
     ]
    }
   ],
   "source": [
    "# plot_valid = []\n",
    "# hidden = None\n",
    "n_itter = 500\n",
    "\n",
    "# learner = Learner(cuda(RNN(len(data.decoder), 150, 1)),None,nn.NLLLoss(),data)\n",
    "learner,plot_valid,hidden = train_model(learner,data,n_itter,lr,bs,plot_valid,hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_seq(model,Data,sql,symbol='^'):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        hidden = model.initHidden(1)\n",
    "        result = symbol\n",
    "        for i in range(sql):\n",
    "            x = cuda(onehencode(symbol,Data.encoder))\n",
    "            output, hidden = model.forward(x,hidden)        \n",
    "            hidden = hidden.detach()\n",
    "            \n",
    "            prob     = np.exp(output[0].cpu().numpy())\n",
    "            cum_prob = np.cumsum(prob)\n",
    "            idx      = np.where(cum_prob - random.random() > 0)[0][0]\n",
    "            symbol   = Data.decoder[idx]\n",
    "            result  += symbol\n",
    "    model.train()\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^Rap the as of the out inentherd IREuT gangse sort reats, De ho what of toe nutiol of for anot!€htthers. Aplise ip willed to se with Harsteray.€.€. Thakal Co ruald s opas and yot then iving fastipsioul\n"
     ]
    }
   ],
   "source": [
    "generate_seq(learner.model,data,200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(data.decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4096, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(plot_valid[1:-1])\n",
    "plt.show()\n",
    "print(plot_valid[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "# plt.plot(Plots.valid1[1:-1])\n",
    "plt.plot(Plots.valid2[1:-1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### experimenting with save/load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_checkpoint({\n",
    "            'epoch': epoch,\n",
    "            'arch': \"1_RNN\",\n",
    "            'state_dict': rnn.state_dict(),\n",
    "            'hd_sz': rnn.hd_sz,\n",
    "            'in_sz': rnn.in_sz,\n",
    "            'out_sz': rnn.out_sz,\n",
    "            'loss': loss,\n",
    "            'best_prec1': None,\n",
    "            'optimizer' : None,\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn2, epoch, loss = load_checkpoint(filename='models/checkpoint.pth.tar')\n",
    "rnn2.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### functions I should not need anymore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_parentbatch(tweets, bs, sql, symbol='£'):\n",
    "    f\"\"\"each parent-batch will have different numbers of sub-batches depending on how long the tweets are\"\"\"\n",
    "    assert(len(tweets)/bs*10%2==0)\n",
    "    bch_strs = batch_strings(tweets,bs,sql)\n",
    "    parent_batches = []\n",
    "    for pb in range(len(bch_strs)):\n",
    "        bch       = bch_strs[pb]\n",
    "        n_tweet   = bs\n",
    "        n_segment = math.ceil(len(bch[0])/sql)\n",
    "        sbx = torch.zeros(n_tweet,n_segment,sql,len(data.decoder))\n",
    "        sby = torch.zeros(n_tweet,n_segment,sql).long()\n",
    "\n",
    "        for tweet in range(n_tweet):\n",
    "            if re.search(symbol,bch[tweet]): position = re.search(symbol,bch[tweet]).span()[0]\n",
    "            else:                            position = len(bch[tweet])\n",
    "            x_str = change_char(bch[tweet],position-1,symbol)\n",
    "            y_str = bch[tweet][1:len(bch[tweet])]+symbol                \n",
    "            for segment in range(n_segment):\n",
    "                x = x_str[sql*segment:sql*(segment+1)]\n",
    "                y = y_str[sql*segment:sql*(segment+1)]  \n",
    "                sbx[tweet,segment] = encodestr(x,data.encoder)\n",
    "                sby[tweet,segment] = torch.Tensor([data.encoder[char] for char in y])                \n",
    "                \n",
    "        sb_ds = SBDataLoader(sbx, sby)\n",
    "        parent_batches.append(sb_ds)\n",
    "    return parent_batches\n",
    "\n",
    "class ParentDataLoader():\n",
    "    def __init__(self, ds): \n",
    "        self.ds = ds\n",
    "    def __iter__(self):    \n",
    "        for i in range(len(self.ds)):\n",
    "            iterator = iter(self.ds[i])\n",
    "            yield next(iterator), True\n",
    "            try:\n",
    "                while True:                \n",
    "                    yield next(iterator), False \n",
    "            except StopIteration:\n",
    "                pass\n",
    "            \n",
    "            def init_params(in_sz, bs, hd_sz=150):\n",
    "    Params = Struct()\n",
    "    Params.ni      = 3000\n",
    "    Params.ne      = 1\n",
    "    Params.hd_sz   = hd_sz\n",
    "    Params.in_sz   = in_sz\n",
    "    Params.sql     = 10\n",
    "    Params.iv_pr   = 200\n",
    "    Params.iv_pl   = 100\n",
    "    Params.n_e     = 1\n",
    "    Params.n_i     = 1000\n",
    "    Params.use_opt = True \n",
    "    Params.lr      = 0.0005\n",
    "    Params.bs      = bs\n",
    "    return Params"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
