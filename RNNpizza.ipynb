{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device cuda:0\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import time\n",
    "import copy\n",
    "import math \n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "# from torchviz import make_dot\n",
    "\n",
    "cuda_available = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if cuda_available else \"cpu\")\n",
    "print(f'''using device {device}''')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import numpy as np\n",
    "import pickle\n",
    "import random \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.OutputArea.auto_scroll_threshold = 9999;\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.auto_scroll_threshold = 9999;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def usecuda(input):\n",
    "    if torch.cuda.is_available(): return input.cuda()\n",
    "    return input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/r2/Documents/RNNexp\n"
     ]
    }
   ],
   "source": [
    "path = !pwd\n",
    "path = path[0]\n",
    "print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.read_pickle(path+\"/data/step3_DAT_MT_USDJPY_M1_2018_merged_pickled\") \n",
    "# data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Struct():\n",
    "    pass \n",
    "\n",
    "\n",
    "\n",
    "def pp_trumpdata(filename, prop, bsize=1):\n",
    "    Data, train, valid, test = Struct(), Struct(), Struct(), Struct()        \n",
    "    tweets, tweet_str, Data.decoder, Data.encoder = load_trumpdata(filename)    \n",
    "\n",
    "    train.tweets = tweets[0:round(prop[0]*len(tweets))]\n",
    "    train.tweet_str = tweet_str[0:round(prop[1]*len(tweet_str))]    \n",
    "    valid.tweets = tweets[round(prop[0]*len(tweets)):round(prop[1]*len(tweets))]\n",
    "    valid.tweet_str = tweet_str[round(prop[0]*len(tweet_str)):round(prop[1]*len(tweet_str))]    \n",
    "    test.tweets  = tweets[round(prop[1]*len(tweets)):-1]\n",
    "    test.tweet_str  = tweet_str[round(prop[1]*len(tweet_str)):-1]    \n",
    "\n",
    "    train.batch_str = []\n",
    "    stepsize = round(len(train.tweet_str)/bsize-1)\n",
    "    for i in range(0,bsize):\n",
    "        train.batch_str.append(train.tweet_str[i*stepsize:(i+1)*stepsize])\n",
    "    valid.batch_str = [valid.tweet_str]\n",
    "    \n",
    "    Data.train, Data.valid, Data.test, Data.bsize = train, valid, test, bsize\n",
    "    return Data\n",
    "\n",
    "def onehencode(symbol, encoder):\n",
    "    x = torch.zeros(len(encoder),1)\n",
    "    x[encoder[symbol]] = 1.0\n",
    "    return usecuda(x.t())\n",
    "\n",
    "def encodestr(string, encoder, seq_len):\n",
    "    x = torch.zeros((seq_len,len(encoder)))\n",
    "    x[[idx for idx in range(0,seq_len)],[encoder[char] for char in string]] = 1\n",
    "    return usecuda(x)\n",
    "\n",
    "def generate_seq(model, hidden, symbol, seq_len, m, seed):\n",
    "    with torch.no_grad():\n",
    "        result_str = symbol\n",
    "        for i in range(seq_len):\n",
    "            x = onehencode(symbol,encoder)\n",
    "            output, new_hidden = model.forward(x,hidden)\n",
    "        \n",
    "            hidden = new_hidden.detach()\n",
    "            prob = np.exp(output.detach().data.cpu().numpy())\n",
    "            cum_prob = np.cumsum(prob)\n",
    "\n",
    "            a = random.random()\n",
    "            idx = np.where(cum_prob - a > 0)[0][0]\n",
    "            symbol = decoder[idx]\n",
    "            result_str += symbol\n",
    "\n",
    "        return result_str\n",
    "    \n",
    "def save_checkpoint(state, filename='models/checkpoint.pth.tar'):\n",
    "    torch.save(state, filename)\n",
    "\n",
    "def load_checkpoint(filename='models/checkpoint.pth.tar'):\n",
    "    checkpoint = torch.load(filename)    \n",
    "    for item in iter(checkpoint):\n",
    "        print(item)\n",
    "    model = RNN(checkpoint['in_sz'],checkpoint['hd_sz'],checkpoint['out_sz'])\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    #     optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    epoch = checkpoint['epoch']\n",
    "    loss = checkpoint['loss']\n",
    "    return model, epoch, loss    \n",
    "\n",
    "def get_valid_loss(model,Data,Params,seq_len,ntweet):\n",
    "    start = time.time()\n",
    "    loss_valid = 0\n",
    "    hidden = usecuda(torch.zeros(1,model.hd_sz))\n",
    "    with torch.no_grad():    \n",
    "        model.eval()\n",
    "        for t in range(ntweet):\n",
    "            tweet = Data.valid.tweets[t]\n",
    "            xv, yv = generate_valid(Data,tweet,seq_len)     \n",
    "            loss = 0\n",
    "            for char in range(xv.size()[1]):\n",
    "                x = xv[:,char,:].reshape(xv.shape[0],xv.shape[2])\n",
    "                output, hidden = model.forward(x,hidden)\n",
    "                y = yv[:,char,:]\n",
    "                loss += criterion(output,y.reshape(xv.shape[0]))\n",
    "            loss_valid += loss/(xv.size()[2])\n",
    "    print(f\"calculating validation loss took {time.time()-start:.2f} seconds\")\n",
    "    return loss_valid/ntweet\n",
    "\n",
    "def parse_hidden(x,hidden,Data,symbol='*'):\n",
    "    # use .data to not break the connection to the graph     \n",
    "    for i in range(0,x.shape[0]):\n",
    "        if onehdecode(x[i,:],Data.decoder) == symbol:\n",
    "            hidden.data[i,:] = torch.zeros(1,hidden.shape[1])\n",
    "    return hidden\n",
    "\n",
    "def train_batch(model,X,Y,Data,hidden,lr,optimizer,use_opt,update_hidden):\n",
    "    model.train()\n",
    "    if use_opt: optimizer.zero_grad() \n",
    "    else: model.zero_grad()\n",
    "    loss = 0\n",
    "    for char in range(X.size()[1]):\n",
    "        x = X[:,char,:].reshape(X.shape[0],X.shape[2])\n",
    "        if update_hidden: hidden = parse_hidden(x,hidden,Data,symbol='*')        \n",
    "        output, hidden = model.forward(x,hidden)\n",
    "        y = Y[:,char,:]\n",
    "        loss += criterion(output,y.reshape(X.shape[0]))\n",
    "    loss.backward()\n",
    "    if use_opt: optimizer.step()\n",
    "    else:\n",
    "        for p in model.parameters(): p.data.add_(-lr, p.grad.data)\n",
    "    # hidden.detach() because we are done with training...\n",
    "    return loss/(X.size()[2]), hidden.detach()\n",
    "\n",
    "def generate_valid(Data, tweet, seq_len):\n",
    "    if seq_len > len(tweet)-1: seq_len = len(tweet)-1    \n",
    "    X = torch.zeros(1,seq_len,len(Data.encoder))\n",
    "    Y = torch.zeros(1,seq_len,1)  \n",
    "    x = encodestr(tweet[0:seq_len],Data.encoder,seq_len)\n",
    "    y = torch.Tensor([Data.encoder[char] for char in tweet[1:seq_len+1]])\n",
    "    X[0,:,:] = x.reshape(seq_len,len(Data.encoder))\n",
    "    Y[0,:,:] = y.reshape(seq_len,1)\n",
    "    return usecuda(X),usecuda(Y.long())\n",
    "\n",
    "def generate_batch(e, Data, seq_len, get_valid=False):\n",
    "    if get_valid: \n",
    "        batch_str, bsize = Data.valid.batch_str, 1        \n",
    "    else: batch_str, bsize = Data.train.batch_str, Data.bsize\n",
    "    X = torch.zeros(bsize,seq_len,len(Data.encoder))\n",
    "    Y = torch.zeros(bsize,seq_len,1)\n",
    "    for i in range(0,bsize):        \n",
    "        x = encodestr(batch_str[i][e:e+seq_len],Data.encoder,seq_len)\n",
    "        y = torch.Tensor([Data.encoder[char] for char in batch_str[i][e+1:e+seq_len+1]])\n",
    "        X[i,:,:] = x.reshape(seq_len,len(Data.encoder))\n",
    "        Y[i,:,:] = y.reshape(seq_len,1)\n",
    "    return usecuda(X),usecuda(Y.long())\n",
    "\n",
    "def do_training(model,Data,Params,optimizer,update_hidden,Plots=0):\n",
    "    if Plots==0:\n",
    "        Plots = Struct()\n",
    "        Plots.loss_train, Plots.loss_valid = [], []\n",
    "    start      = time.time()\n",
    "    loss_train = 0\n",
    "    hidden     = usecuda(torch.zeros(Params.bsize,model.hd_sz))\n",
    "    for epoch in range(Params.ne):\n",
    "        char_idx = 0\n",
    "        i = 0 \n",
    "        while i < Params.ni and char_idx < len(Data.train.batch_str[0])-Params.seq_len-1:\n",
    "            X,Y          = generate_batch(char_idx, Data, Params.seq_len,False)\n",
    "            loss, hidden = train_batch(model,X,Y,Data,hidden,Params.lr,optimizer,True,update_hidden)\n",
    "            loss_train  += loss         \n",
    "            if i%Params.iv_pl  == 0:  \n",
    "                Plots.loss_valid.append(get_valid_loss(model,Data,Params,30,50))\n",
    "                print(Plots.loss_valid[-1])\n",
    "                Plots.loss_train.append(loss_train/Params.iv_pl)\n",
    "                loss_train = 0 \n",
    "            char_idx += Params.seq_len + 1\n",
    "            i        += 1\n",
    "        print(f\"\"\"\\n epoch {epoch+1} took {time.time() - start:.2f} seconds\"\"\")  \n",
    "    return Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## my RNN module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNN,self).__init__()\n",
    "        self.hd_sz  = hidden_size\n",
    "        self.in_sz  = input_size\n",
    "        self.out_sz = output_size\n",
    "        \n",
    "        self.h1 = nn.Linear(input_size + hidden_size, hidden_size)        \n",
    "        self.o1 = nn.Linear(input_size + hidden_size, input_size)\n",
    "        \n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "        \n",
    "    def forward(self, input, hidden):\n",
    "        combined = torch.cat((input, hidden), 1)\n",
    "        hidden = torch.tanh(self.h1(combined))\n",
    "        output = self.o1(combined)\n",
    "        output = self.softmax(output)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(hidden_layers[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = pp_trumpdata(path+\"/data/trump/\", [0.9,0.95], 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "Params = Struct()\n",
    "Params.hd_sz   = 150\n",
    "Params.in_sz   = len(Data.encoder)\n",
    "Params.seq_len = 30\n",
    "Params.iv_pr   = 200\n",
    "Params.iv_pl   = 100\n",
    "Params.ne      = 1\n",
    "Params.ni      = 1000\n",
    "Params.use_opt = True \n",
    "Params.lr      = 0.0005\n",
    "Params.bsize   = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### padding functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad(str_list,max_len=0,token='%'):\n",
    "    if max_len == 0: max_len = len((max(str_list, key=len)))\n",
    "    for idx, row in enumerate(str_list):        \n",
    "        str_list[idx] = row + token*(max_len-len(row))\n",
    "    if len(str_list) == 1: return str_list[0]\n",
    "    return str_list\n",
    "\n",
    "def batch_strings(tweets,bs):\n",
    "    bch_strs = [] \n",
    "    for i in range(round(len(tweets)/bs)):\n",
    "        print(i)\n",
    "        bch_strs.append(pad(tweets[i*bs:(i+1)*bs]))\n",
    "    return bch_strs\n",
    "\n",
    "def process(bch_strs, sql):\n",
    "    f\"\"\"each parent-batch will have different numbers of sub-batches depending on how long the tweets are\"\"\"\n",
    "#     [parent_batch](x,y)[]\n",
    "    parent_batches = []\n",
    "    for pb in range(len(bch_strs)):\n",
    "        n_sb   = len(bch_strs[pb])\n",
    "        n_strs = math.ceil(len(bch_strs[pb][0])/sql)\n",
    "        sbx = torch.zeros(n_strs,n_sb,sql,len(Data.decoder))\n",
    "        sby = torch.zeros(n_strs,n_sb,sql,1)\n",
    "        for i in range(0,len(bch_strs[pb][0]),sql):         \n",
    "            if i+sql > len(bch_strs[pb][0])-1: endchar = len(bch_strs[pb][0])\n",
    "            else: endchar = i+sql                \n",
    "            for sb in range(len(bch_strs[pb])):\n",
    "                x_str, y_str = bch_strs[pb][sb][i:endchar-1], bch_strs[pb][sb][i+1:endchar]\n",
    "                if len(x_str) < sql: x_str, y_str = pad([x_str],sql),pad([y_str],sql)                                 \n",
    "                x = encodestr(x_str,Data.encoder,len(x_str))\n",
    "                y = torch.Tensor([Data.encoder[char] for char in y_str])\n",
    "                sbx[int(i/sql),sb], sby[int(i/sql),sb] = x,y.unsqueeze(1)\n",
    "        parent_batches.append((sbx,sby))\n",
    "    return parent_batches\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_trumpdata(datapath, pad_tok='£', start_tok='^', end_tok='€'):\n",
    "    import json \n",
    "    van_tws, tws, van_tw_str, tw_str = [],[],'',''\n",
    "    filenames = ['condensed_2018.json', 'condensed_2016.json', 'condensed_2017.json', 'condensed_2018.json']\n",
    "    for fname in filenames:\n",
    "        f = open(datapath+fname,\"r\")\n",
    "        data = f.readline()\n",
    "        f.close()\n",
    "        data_tr = json.loads(data)\n",
    "        for line in range(0,len(data_tr)):\n",
    "            tweet     = data_tr[line][\"text\"].rstrip('\\\\')\n",
    "            van_tw_str = van_tw_str + tweet \n",
    "            van_tws.append(tweet)            \n",
    "    symbols = list(set(van_tw_str))  \n",
    "    assert(pad_tok not in symbols)\n",
    "    assert(start_tok not in symbols)\n",
    "    assert(end_tok not in symbols)\n",
    "\n",
    "    for tweet in van_tweets:\n",
    "        pad_tweet = start_tok + tweet + end_tok\n",
    "        tw_str    = tw_str + pad_tweet            \n",
    "    symbols = [pad_tok] + symbols + [start_tok, end_tok]\n",
    "    \n",
    "    decoder = {idx: symbols[idx] for idx in range(0,len(symbols))}\n",
    "    encoder = {symbols[idx]: idx for idx in range(0,len(symbols))}        \n",
    "    return tweets, tweet_str, decoder, encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "£\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "data = load_trumpdata(path+\"/data/trump/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_NLLLoss(torch.nn.Module):\n",
    "    # I assume here that I need the backwardspass from \n",
    "    # the NLLLoss because I use it in a chain-calculation\n",
    "    # in my RNN-network     \n",
    "    \n",
    "    def __init__(self):\n",
    "        super(NLLLoss,self).__init__()\n",
    "        \n",
    "    def forward(self,x,y):\n",
    "        \n",
    "    \n",
    "    # two steps: \n",
    "    # (i)  turn y into oneh encoded \n",
    "    # (ii) compare y_hat to y \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Dataset():\n",
    "    def __init__(self, x, y): self.x,self.y = x,y\n",
    "    def __len__(self): return len(self.x)\n",
    "    def __getitem__(self, i): return self.x[i],self.y[i]\n",
    "\n",
    "def get_dls(train_ds, valid_ds, tbs, vbs, **kwargs):\n",
    "    return (DataLoader(train_ds, batch_size=tbs, **kwargs),\n",
    "            DataLoader(valid_ds, batch_size=vbs, **kwargs))\n",
    "\n",
    "\n",
    "class DataLoader():\n",
    "    def __init__(self, ds, bs): self.ds, self.bs = ds,bs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating validation loss took 0.31 seconds\n",
      "tensor(0.5009, device='cuda:0')\n",
      "calculating validation loss took 0.31 seconds\n",
      "tensor(0.3001, device='cuda:0')\n",
      "calculating validation loss took 0.31 seconds\n",
      "tensor(0.2965, device='cuda:0')\n",
      "calculating validation loss took 0.31 seconds\n",
      "tensor(0.2922, device='cuda:0')\n",
      "calculating validation loss took 0.31 seconds\n",
      "tensor(0.2873, device='cuda:0')\n",
      "calculating validation loss took 0.31 seconds\n",
      "tensor(0.2848, device='cuda:0')\n",
      "calculating validation loss took 0.31 seconds\n",
      "tensor(0.2778, device='cuda:0')\n",
      "calculating validation loss took 0.31 seconds\n",
      "tensor(0.2730, device='cuda:0')\n",
      "calculating validation loss took 0.31 seconds\n",
      "tensor(0.2690, device='cuda:0')\n",
      "calculating validation loss took 0.31 seconds\n",
      "tensor(0.2649, device='cuda:0')\n",
      "\n",
      " epoch 1 took 21.58 seconds\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(24)\n",
    "rnn1 = usecuda(RNN(Params.in_sz, Params.hd_sz, 1))\n",
    "torch.manual_seed(24)\n",
    "rnn2 = usecuda(RNN(Params.in_sz, Params.hd_sz, 1))\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "optimizer1 = optim.RMSprop(rnn1.parameters(), lr=Params.lr)\n",
    "optimizer2 = optim.RMSprop(rnn2.parameters(), lr=Params.lr)\n",
    "\n",
    "Params1 = copy.deepcopy(Params)\n",
    "Params2 = copy.deepcopy(Params)\n",
    "Params1.bsize = 10\n",
    "Params2.bsize = 10\n",
    "\n",
    "Data1 = pp_trumpdata(path+\"/data/trump/\", [0.9,0.95], Params1.bsize)\n",
    "Data2 = pp_trumpdata(path+\"/data/trump/\", [0.9,0.95], Params2.bsize)\n",
    "\n",
    "# Plots1 = do_training(rnn1,Data1,Params1,optimizer1,True)\n",
    "Plots2 = do_training(rnn2,Data2,Params2,optimizer2,False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(Plots1.loss_valid[1:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(Plots2.loss_valid[1:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehdecode(vector, decoder):\n",
    "    val, idx = torch.max(vector,0)\n",
    "    return decoder[idx.item()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_checkpoint({\n",
    "            'epoch': epoch,\n",
    "            'arch': \"1_RNN\",\n",
    "            'state_dict': rnn.state_dict(),\n",
    "            'hd_sz': rnn.hd_sz,\n",
    "            'in_sz': rnn.in_sz,\n",
    "            'out_sz': rnn.out_sz,\n",
    "            'loss': loss,\n",
    "            'best_prec1': None,\n",
    "            'optimizer' : None,\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn2, epoch, loss = load_checkpoint(filename='models/checkpoint.pth.tar')\n",
    "rnn2.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(generate_seq(rnn2, torch.zeros(1,hsize).cuda(),'T',100,m,42))\n",
    "print(generate_seq(rnn, torch.zeros(1,hsize).cuda(),'T',100,m,42))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### build RNN network with LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### cut input into seq length bits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[['Open','High','Low','Close']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff = 0.2\n",
    "set_train = data[0:round(len(data)*cutoff)]\n",
    "set_test  = data[round(len(data)*cutoff):-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sz = set_train.shape[1]\n",
    "hidden_sz = 100\n",
    "output_sz = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = RNN(input_sz, hidden_sz, output_sz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for index, row in set_train.iterrows():\n",
    "#     print(np.array(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.005\n",
    "\n",
    "def train(X,Y)\n",
    "    hidden = rnn.initHidden()\n",
    "    \n",
    "    rnn.zero_grad()\n",
    "    \n",
    "    for i in range(X.size()[0]):\n",
    "        output, hidden = rnn(X[i], hidden)\n",
    "        \n",
    "    loss = criterion(output, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
