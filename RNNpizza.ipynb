{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device cuda:0\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import time\n",
    "import copy\n",
    "import math \n",
    "import re\n",
    "import json \n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "import pickle\n",
    "import random \n",
    "import pandas as pd\n",
    "\n",
    "from functools import partial \n",
    "\n",
    "cuda_available = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if cuda_available else \"cpu\")\n",
    "print(f'''using device {device}''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.OutputArea.auto_scroll_threshold = 9999;\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.auto_scroll_threshold = 9999;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cuda(input):\n",
    "    if torch.cuda.is_available(): return input.cuda()\n",
    "    return input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/r2/Documents/RNNexp\n"
     ]
    }
   ],
   "source": [
    "path = !pwd\n",
    "path = path[0]\n",
    "print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.read_pickle(path+\"/data/step3_DAT_MT_USDJPY_M1_2018_merged_pickled\") \n",
    "# data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Struct():\n",
    "    pass \n",
    "\n",
    "def load_trumpdata(datapath, pad_tok='£', start_tok='^', end_tok='€'):\n",
    "\n",
    "    van_tws, tws, van_tw_str, tw_str = [],[],'',''\n",
    "    filenames = ['condensed_2018.json', 'condensed_2016.json', 'condensed_2017.json', 'condensed_2018.json']\n",
    "    for fname in filenames:\n",
    "        f = open(datapath+fname,\"r\")\n",
    "        data = f.readline()\n",
    "        f.close()\n",
    "        data_tr = json.loads(data)\n",
    "        for line in range(0,len(data_tr)):\n",
    "            tweet      = data_tr[line][\"text\"].rstrip('\\\\')\n",
    "            van_tw_str = van_tw_str + tweet \n",
    "            van_tws.append(tweet)            \n",
    "    symbols = list(set(van_tw_str))  \n",
    "    assert(pad_tok   not in symbols)\n",
    "    assert(start_tok not in symbols)\n",
    "    assert(end_tok   not in symbols)\n",
    "\n",
    "    for tweet in van_tws:\n",
    "        pad_tweet = start_tok + tweet + end_tok\n",
    "        tw_str    = tw_str + pad_tweet            \n",
    "        tws.append(pad_tweet)        \n",
    "    symbols = [pad_tok, start_tok] + symbols + [end_tok]   \n",
    "    decoder = {idx: symbols[idx] for idx in range(0,len(symbols))}\n",
    "    encoder = {symbols[idx]: idx for idx in range(0,len(symbols))}        \n",
    "    return tws, tw_str, decoder, encoder\n",
    "\n",
    "def pp_trumpdata(filename, prop, bsize=1):\n",
    "    Data, train, valid, test = Struct(), Struct(), Struct(), Struct()        \n",
    "    tweets, tweet_str, Data.decoder, Data.encoder = load_trumpdata(filename)    \n",
    "\n",
    "    train.tweets = tweets[0:round(prop[0]*len(tweets))]\n",
    "    train.tweet_str = tweet_str[0:round(prop[1]*len(tweet_str))]    \n",
    "    valid.tweets = tweets[round(prop[0]*len(tweets)):round(prop[1]*len(tweets))]\n",
    "    valid.tweet_str = tweet_str[round(prop[0]*len(tweet_str)):round(prop[1]*len(tweet_str))]    \n",
    "    test.tweets  = tweets[round(prop[1]*len(tweets)):-1]\n",
    "    test.tweet_str  = tweet_str[round(prop[1]*len(tweet_str)):-1]    \n",
    "\n",
    "    train.batch_str = []\n",
    "    stepsize = round(len(train.tweet_str)/bsize-1)\n",
    "    for i in range(0,bsize):\n",
    "        train.batch_str.append(train.tweet_str[i*stepsize:(i+1)*stepsize])\n",
    "    valid.batch_str = [valid.tweet_str]\n",
    "    \n",
    "    Data.train, Data.valid, Data.test, Data.bsize = train, valid, test, bsize\n",
    "    return Data\n",
    "\n",
    "def save_checkpoint(state, filename='models/checkpoint.pth.tar'):\n",
    "    torch.save(state, filename)\n",
    "\n",
    "def load_checkpoint(filename='models/checkpoint.pth.tar'):\n",
    "    checkpoint = torch.load(filename)    \n",
    "    for item in iter(checkpoint):\n",
    "        print(item)\n",
    "    model = RNN(checkpoint['in_sz'],checkpoint['hd_sz'],checkpoint['out_sz'])\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    #     optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    epoch = checkpoint['epoch']\n",
    "    loss = checkpoint['loss']\n",
    "    return model, epoch, loss    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### encoder/decoders "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encodestr(string, encoder):\n",
    "    x = torch.zeros((len(string),len(encoder)))\n",
    "    x[[idx for idx in range(0,len(string))],[encoder[char] for char in string]] = 1\n",
    "    return x\n",
    "\n",
    "def onehencode(symbol, encoder):\n",
    "    x = torch.zeros(len(encoder),1)\n",
    "    x[encoder[symbol]] = 1.0\n",
    "    return x.t()\n",
    "\n",
    "def encode(string, encoder):\n",
    "    return torch.Tensor([encoder[char] for char in y_str])\n",
    "\n",
    "def onehdecode(X,decoder):\n",
    "    assert(X.shape[-1] == len(decoder))\n",
    "    string = ''\n",
    "    for char in range(X.shape[0]):\n",
    "        val, idx = torch.max(X[char],0)\n",
    "        string += decoder[idx.item()]\n",
    "    print(string)\n",
    "    \n",
    "def ydecode(Y,decoder):\n",
    "    string = ''\n",
    "    for char in range(Y.shape[0]): string += decoder[Y[char].item()]\n",
    "    print(string)\n",
    "\n",
    "def change_char(s, p, r):\n",
    "    return s[:p]+r+s[p+1:] \n",
    "\n",
    "def generate_seq(model,Data,sql,symbol='^'):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        hidden = model.initHidden(1)\n",
    "        result = symbol\n",
    "        for i in range(sql):\n",
    "            x = cuda(onehencode(symbol,Data.encoder))\n",
    "            output, hidden = model.forward(x,hidden)        \n",
    "            hidden = hidden.detach()\n",
    "            \n",
    "            prob     = np.exp(output[0].cpu().numpy())\n",
    "            cum_prob = np.cumsum(prob)\n",
    "            idx      = np.where(cum_prob - random.random() > 0)[0][0]\n",
    "            symbol   = Data.decoder[idx]\n",
    "            result  += symbol\n",
    "    model.train()\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## my RNN module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNoriginal(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNNoriginal,self).__init__()\n",
    "        self.hd_sz  = hidden_size\n",
    "        self.in_sz  = input_size\n",
    "        self.out_sz = output_size\n",
    "        \n",
    "        self.h1  = nn.Linear(input_size + hidden_size, hidden_size)               \n",
    "        self.o1   = nn.Linear(input_size + hidden_size, input_size)\n",
    "\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "        \n",
    "    def forward(self, input, hidden):\n",
    "        combined = torch.cat((input, hidden), 1)    \n",
    "        \n",
    "        hidden   = self.h1(combined)\n",
    "        hidden   = torch.tanh(hidden)\n",
    "        \n",
    "        output   = self.o1(combined)\n",
    "        output   = self.softmax(output)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self,bs):\n",
    "        return cuda(torch.zeros(bs,self.hd_sz))\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNN,self).__init__()\n",
    "        self.hd_sz  = hidden_size\n",
    "        self.in_sz  = input_size\n",
    "        self.out_sz = output_size\n",
    "        \n",
    "        combined = input_size+hidden_size\n",
    "        \n",
    "        self.h1      = nn.Linear(combined, hidden_size)               \n",
    "\n",
    "        self.o1      = nn.Linear(combined, combined)\n",
    "        self.bn1     = nn.BatchNorm1d(combined)\n",
    "        self.relu    = nn.ReLU(combined)\n",
    "\n",
    "        self.o2      = nn.Linear(combined, input_size)\n",
    "        self.bn2     = nn.BatchNorm1d(input_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "        \n",
    "    def forward(self, input, hidden):\n",
    "        combined = torch.cat((input, hidden), 1)    \n",
    "        \n",
    "        hidden   = self.h1(combined)\n",
    "        hidden   = torch.tanh(hidden)\n",
    "        \n",
    "        output   = self.o1(combined)\n",
    "        output   = self.bn1(output)\n",
    "        output   = self.relu(output)\n",
    "        \n",
    "        output   = self.o2(output)\n",
    "        output   = self.bn2(output)\n",
    "        output   = self.softmax(output)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self,bs):\n",
    "        return cuda(torch.zeros(bs,self.hd_sz))\n",
    "\n",
    "def weights_init_uniform(m):\n",
    "    classname = m.__class__.__name__\n",
    "    # for every Linear layer in a model..\n",
    "    if classname.find('Linear') != -1:\n",
    "        # apply a uniform distribution to the weights and a bias=0\n",
    "        m.weight.data.uniform_(0.0, 1.0)\n",
    "        m.bias.data.fill_(0)\n",
    "\n",
    "def weights_init_xavier(m):\n",
    "    classname = m.__class__.__name__\n",
    "    # for every Linear layer in a model..\n",
    "    if classname.find('Linear') != -1:\n",
    "        torch.nn.init.xavier_uniform_(m.weight)\n",
    "        m.bias.data.fill_(0.01)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataLoaders, Itterators, DataSets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad(str_list,sql=1,token='£'):\n",
    "    f\"\"\"pad all strings in a list to max_len\"\"\"\n",
    "    max_len = math.ceil(len(max(str_list, key=len))/sql)*sql\n",
    "    for idx, row in enumerate(str_list):        \n",
    "        str_list[idx] = row + token*(max_len-len(row))\n",
    "    if len(str_list) == 1: return str_list[0]\n",
    "    return str_list\n",
    "\n",
    "def mk_tweetbatch(tweets,encoder,bs,sql,symbol='£'):\n",
    "    assert(math.floor(len(tweets)/bs)==len(tweets)/bs)\n",
    "    bch       = batch_strings(tweets,bs,sql)[0]\n",
    "    assert(math.floor(len(bch[0])/sql)==len(bch[0])/sql)            \n",
    "    n_segment = int(len(bch[0])/sql)\n",
    "    sbx       = torch.zeros(bs,n_segment,sql,len(encoder))\n",
    "    sby       = torch.zeros(bs,n_segment,sql).long()\n",
    "    for tweet in range(bs):\n",
    "        \"\"\"for target we don't use first char, compensate with one padded char\"\"\"\n",
    "        y_str = bch[tweet][1:len(bch[tweet])]+symbol      \n",
    "        \n",
    "        chng_pos = len(bch[tweet])\n",
    "        \"\"\"if we find padded char, we know that tweet ended, remove last char of tweet\"\"\"        \n",
    "        if re.search(symbol,bch[tweet]): chng_pos = re.search(symbol,bch[tweet]).span()[0]       \n",
    "        x_str = change_char(bch[tweet],chng_pos-1,symbol)     \n",
    "        \n",
    "        for segment in range(n_segment):\n",
    "            x = x_str[sql*segment:sql*(segment+1)]\n",
    "            y = y_str[sql*segment:sql*(segment+1)]  \n",
    "            sbx[tweet,segment] = encodestr(x,encoder)\n",
    "            sby[tweet,segment] = torch.Tensor([encoder[char] for char in y])                    \n",
    "    return sbx,sby\n",
    "\n",
    "class TweetDataLoader():\n",
    "    def __init__(self,data,tweets,bs,sql,shuffle=False):    \n",
    "        assert(math.floor(len(tweets)/bs)==len(tweets)/bs)\n",
    "        self.tweets  = tweets\n",
    "        self.bs      = bs         \n",
    "        self.sql     = sql\n",
    "        self.encoder = data.encoder\n",
    "        self.decoder = data.decoder\n",
    "        self.i       = -1\n",
    "        self.shuffle = shuffle        \n",
    "        \n",
    "    def reset(self):\n",
    "        if self.shuffle: random.shuffle(self.tweets)\n",
    "        self.i = -1\n",
    "        \n",
    "    def __iter__(self):  \n",
    "        self.reset()\n",
    "        while True:\n",
    "            self.i+=1\n",
    "            twt      = self.tweets[self.i*self.bs:(self.i+1)*self.bs]\n",
    "            sbx,sby  = mk_tweetbatch(twt,self.encoder,self.bs,self.sql)\n",
    "            sbloader = iter(SBDataLoader(sbx,sby))            \n",
    "            try:\n",
    "                while True:                \n",
    "                    yield next(sbloader) \n",
    "            except StopIteration:\n",
    "                pass            \n",
    "            if self.i==round(len(self.tweets)/self.bs)-1: \n",
    "                self.reset()\n",
    "                break\n",
    "\n",
    "class SBDataLoader():\n",
    "    def __init__(self, sbx, sby): \n",
    "        self.sbx, self.sby = sbx, sby\n",
    "    def __iter__(self):\n",
    "        for j in range(self.sbx.shape[1]): yield cuda(self.sbx[:,j]), cuda(self.sby[:,j])\n",
    "\n",
    "def batch_strings(tweets,bs,sql=1):\n",
    "    f\"\"\"creates a list of batchsize-list of strings of same length and sort each batch with longest string first.\"\"\"    \n",
    "    \"\"\"NOT SURE ABOUT THIS OFFSET, BUT THE PREVIOUS CODE ALWAYS MADE A 0\"\"\"\n",
    "    offset = -1*((len(tweets)/bs)*10%2!=0)    \n",
    "#     offset = -1*((math.floor(len(tweets)/bs)==len(tweets)/bs)==0)    \n",
    "    bch_strs = [] \n",
    "    for i in range(round(len(tweets)/bs)+offset):\n",
    "        strings = tweets[i*bs:(i+1)*bs]\n",
    "        strings.sort(key=len,reverse=True)\n",
    "        pad_strings = pad(strings,sql)\n",
    "        bch_strs.append(pad_strings)\n",
    "    return bch_strs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### building FastAI classes to be used with callbacks in future\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Learner():\n",
    "    def __init__(self, model, loss_fn, data, lr):\n",
    "        opt = optim.RMSprop(model.parameters(), lr)\n",
    "        assert(model is not None)\n",
    "        assert(loss_fn is not None)\n",
    "        assert(data is not None)\n",
    "        self.model,self.opt,self.loss_fn,self.data = model,opt,loss_fn,data\n",
    "        \n",
    "\n",
    "class Callback():\n",
    "    def begin_fit(self,learn):\n",
    "        self.learn = learn\n",
    "        return True\n",
    "    def after_fit(self): return True\n",
    "    def begin_epoch(self,epoch):\n",
    "        self.epoch=epoch\n",
    "        return True\n",
    "    def begin_validate(self): return True\n",
    "    def after_epoch(self): return True \n",
    "    def begin_batch(self,xb,yb):\n",
    "        self.xb,self.yb = xb,yb\n",
    "        return True\n",
    "    def after_loss(self,loss):\n",
    "        self.loss=loss\n",
    "        return True\n",
    "    def after_backward(self): return True\n",
    "    def after_step(self): return True\n",
    "\n",
    "class TrainEvalCallback(Callback):\n",
    "    def begin_fit(self):\n",
    "        self.run.n_epochs=0.\n",
    "        self.run.n_iter=0\n",
    "    \n",
    "    def after_batch(self):\n",
    "        if not self.in_train: return\n",
    "        self.run.n_epochs += 1./self.iters\n",
    "        self.run.n_iter   += 1\n",
    "        \n",
    "    def begin_epoch(self):\n",
    "        self.run.n_epochs=self.epoch\n",
    "        self.model.train()\n",
    "        self.run.in_train=True\n",
    "\n",
    "    def begin_validate(self):\n",
    "        self.model.eval()\n",
    "        self.run.in_train=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_rnn(epoches, learn, data, valid_loss=[], nb_itter=0, cb=None):\n",
    "    start = time.time()\n",
    "    for e in range(epoches):\n",
    "        i = 0\n",
    "        for xb, yb in data.train_dl:      \n",
    "            if xb[0,0,1].item() == 1: \n",
    "                hidden = learn.model.initHidden(xb.shape[0])                \n",
    "                print('setting hidden to zero')\n",
    "            print(i)\n",
    "            learn, hidden, loss = one_rnn_batch(learn,xb,yb,hidden)           \n",
    "            if (i%100==0): valid_loss.append(get_valid(learn,data))\n",
    "            i += 1\n",
    "            if i == nb_itter:\n",
    "                break\n",
    "    return learn, hidden, valid_loss\n",
    "\n",
    "def one_rnn_batch(learn,xb,yb,hidden):\n",
    "    loss = 0 \n",
    "    for char in range(xb.shape[1]):\n",
    "        x,y = xb[:,char],yb[:,char]\n",
    "\n",
    "        idx    = zero_idx(y)\n",
    "        if idx is None: break\n",
    "\n",
    "        hidden = hidden[idx]\n",
    "        x      = x[idx]\n",
    "        y      = y[idx]\n",
    "        output,hidden = learn.model.forward(x,hidden)\n",
    "        loss += learn.loss_fn(output,y)                \n",
    "    if loss != 0 and learn.model.training:            \n",
    "        loss.backward()\n",
    "        learn.opt.step()\n",
    "        learn.opt.zero_grad()\n",
    "    return learn, hidden.detach(), loss\n",
    "\n",
    "def get_valid(learn,data):\n",
    "    learn.model.eval()\n",
    "    tot_loss = 0 \n",
    "    nb_it    = 0\n",
    "    with torch.no_grad():\n",
    "        for xb,yb in iter(data.valid_dl):    \n",
    "            if xb[0,0,1].item() == 1: hidden = learn.model.initHidden(xb.shape[0])            \n",
    "            learn, hidden, loss = one_rnn_batch(learn,xb,yb,hidden)  \n",
    "            tot_loss += loss/xb.size()[2]\n",
    "            nb_it    += 1\n",
    "        print(f\"\"\"getting validation\"\"\")\n",
    "    learn.model.train()\n",
    "    return tot_loss/nb_it\n",
    "\n",
    "def zero_idx(y):\n",
    "    idx = (y != 0).nonzero()\n",
    "    if idx.shape[0] < 2: return None\n",
    "    else: idx = idx.squeeze()\n",
    "    return idx\n",
    "\n",
    "def stats(i,valid_loss):\n",
    "    if i%100==0: \n",
    "        valid_loss.append(get_valid_loss(learn.model,data,Params,30,50))\n",
    "    if i%500==0: print(f\"\"\"checkpoint: {i} itterations done in {time.time() - start} seconds\"\"\")\n",
    "    i += 1   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting hidden to zero\n",
      "0\n",
      "getting validation\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "setting hidden to zero\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "setting hidden to zero\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "setting hidden to zero\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "setting hidden to zero\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "setting hidden to zero\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "setting hidden to zero\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "setting hidden to zero\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "setting hidden to zero\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "setting hidden to zero\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "setting hidden to zero\n",
      "100\n",
      "getting validation\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "setting hidden to zero\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "setting hidden to zero\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "setting hidden to zero\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "setting hidden to zero\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "setting hidden to zero\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "setting hidden to zero\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "setting hidden to zero\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "setting hidden to zero\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "setting hidden to zero\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "setting hidden to zero\n",
      "198\n",
      "199\n",
      "200\n",
      "getting validation\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "setting hidden to zero\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "setting hidden to zero\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "setting hidden to zero\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "setting hidden to zero\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "setting hidden to zero\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "setting hidden to zero\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "setting hidden to zero\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "setting hidden to zero\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "setting hidden to zero\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "setting hidden to zero\n",
      "298\n",
      "299\n",
      "300\n",
      "getting validation\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "setting hidden to zero\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "setting hidden to zero\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "setting hidden to zero\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "setting hidden to zero\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "setting hidden to zero\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "setting hidden to zero\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "setting hidden to zero\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "setting hidden to zero\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "setting hidden to zero\n",
      "387\n",
      "388\n",
      "389\n",
      "390\n",
      "391\n",
      "392\n",
      "393\n",
      "394\n",
      "395\n",
      "396\n",
      "setting hidden to zero\n",
      "397\n",
      "398\n",
      "399\n",
      "400\n",
      "getting validation\n",
      "401\n",
      "402\n",
      "403\n",
      "404\n",
      "405\n",
      "406\n",
      "setting hidden to zero\n",
      "407\n",
      "408\n",
      "409\n",
      "410\n",
      "411\n",
      "412\n",
      "413\n",
      "414\n",
      "415\n",
      "416\n",
      "setting hidden to zero\n",
      "417\n",
      "418\n",
      "419\n",
      "420\n",
      "421\n",
      "422\n",
      "423\n",
      "424\n",
      "425\n",
      "426\n",
      "setting hidden to zero\n",
      "427\n",
      "428\n",
      "429\n",
      "430\n",
      "431\n",
      "432\n",
      "433\n",
      "434\n",
      "435\n",
      "436\n",
      "setting hidden to zero\n",
      "437\n",
      "438\n",
      "439\n",
      "440\n",
      "441\n",
      "442\n",
      "443\n",
      "444\n",
      "445\n",
      "446\n",
      "setting hidden to zero\n",
      "447\n",
      "448\n",
      "449\n",
      "450\n",
      "451\n",
      "452\n",
      "453\n",
      "454\n",
      "455\n",
      "456\n",
      "setting hidden to zero\n",
      "457\n",
      "458\n",
      "459\n",
      "460\n",
      "461\n",
      "462\n",
      "463\n",
      "464\n",
      "465\n",
      "466\n",
      "setting hidden to zero\n",
      "467\n",
      "468\n",
      "469\n",
      "470\n",
      "471\n",
      "472\n",
      "473\n",
      "474\n",
      "475\n",
      "476\n",
      "setting hidden to zero\n",
      "477\n",
      "478\n",
      "479\n",
      "480\n",
      "481\n",
      "482\n",
      "483\n",
      "484\n",
      "485\n",
      "486\n",
      "setting hidden to zero\n",
      "487\n",
      "488\n",
      "489\n",
      "490\n",
      "491\n",
      "492\n",
      "493\n",
      "494\n",
      "495\n",
      "496\n",
      "setting hidden to zero\n",
      "497\n",
      "498\n",
      "499\n",
      "500\n",
      "getting validation\n",
      "501\n",
      "502\n",
      "503\n",
      "504\n",
      "505\n",
      "506\n",
      "setting hidden to zero\n",
      "507\n",
      "508\n",
      "509\n",
      "510\n",
      "511\n",
      "512\n",
      "513\n",
      "514\n",
      "515\n",
      "516\n",
      "setting hidden to zero\n",
      "517\n",
      "518\n",
      "519\n",
      "520\n",
      "521\n",
      "522\n",
      "523\n",
      "524\n",
      "525\n",
      "526\n",
      "setting hidden to zero\n",
      "527\n",
      "528\n",
      "529\n",
      "530\n",
      "531\n",
      "532\n",
      "533\n",
      "534\n",
      "535\n",
      "536\n",
      "setting hidden to zero\n",
      "537\n",
      "538\n",
      "539\n",
      "540\n",
      "541\n",
      "542\n",
      "543\n",
      "544\n",
      "545\n",
      "546\n",
      "setting hidden to zero\n",
      "547\n",
      "548\n",
      "549\n",
      "550\n",
      "551\n",
      "552\n",
      "553\n",
      "554\n",
      "555\n",
      "setting hidden to zero\n",
      "556\n",
      "557\n",
      "558\n",
      "559\n",
      "560\n",
      "561\n",
      "562\n",
      "563\n",
      "564\n",
      "565\n",
      "setting hidden to zero\n",
      "566\n",
      "567\n",
      "568\n",
      "569\n",
      "570\n",
      "571\n",
      "572\n",
      "573\n",
      "574\n",
      "575\n",
      "setting hidden to zero\n",
      "576\n",
      "577\n",
      "578\n",
      "579\n",
      "580\n",
      "581\n",
      "582\n",
      "setting hidden to zero\n",
      "583\n",
      "584\n",
      "585\n",
      "586\n",
      "587\n",
      "588\n",
      "589\n",
      "590\n",
      "591\n",
      "592\n",
      "setting hidden to zero\n",
      "593\n",
      "594\n",
      "595\n",
      "596\n",
      "597\n",
      "598\n",
      "599\n",
      "600\n",
      "getting validation\n",
      "601\n",
      "602\n",
      "setting hidden to zero\n",
      "603\n",
      "604\n",
      "605\n",
      "606\n",
      "607\n",
      "608\n",
      "609\n",
      "610\n",
      "611\n",
      "612\n",
      "setting hidden to zero\n",
      "613\n",
      "614\n",
      "615\n",
      "616\n",
      "617\n",
      "618\n",
      "619\n",
      "620\n",
      "621\n",
      "622\n",
      "setting hidden to zero\n",
      "623\n",
      "624\n",
      "625\n",
      "626\n",
      "627\n",
      "628\n",
      "629\n",
      "630\n",
      "631\n",
      "632\n",
      "633\n",
      "setting hidden to zero\n",
      "634\n",
      "635\n",
      "636\n",
      "637\n",
      "638\n",
      "639\n",
      "640\n",
      "641\n",
      "642\n",
      "643\n",
      "setting hidden to zero\n",
      "644\n",
      "645\n",
      "646\n",
      "647\n",
      "648\n",
      "649\n",
      "650\n",
      "651\n",
      "652\n",
      "653\n",
      "setting hidden to zero\n",
      "654\n",
      "655\n",
      "656\n",
      "657\n",
      "658\n",
      "659\n",
      "660\n",
      "661\n",
      "662\n",
      "663\n",
      "setting hidden to zero\n",
      "664\n",
      "665\n",
      "666\n",
      "667\n",
      "668\n",
      "669\n",
      "670\n",
      "671\n",
      "672\n",
      "673\n",
      "674\n",
      "setting hidden to zero\n",
      "675\n",
      "676\n",
      "677\n",
      "678\n",
      "679\n",
      "680\n",
      "681\n",
      "682\n",
      "683\n",
      "684\n",
      "setting hidden to zero\n",
      "685\n",
      "686\n",
      "687\n",
      "688\n",
      "689\n",
      "690\n",
      "691\n",
      "692\n",
      "693\n",
      "694\n",
      "setting hidden to zero\n",
      "695\n",
      "696\n",
      "697\n",
      "698\n",
      "699\n",
      "700\n",
      "getting validation\n",
      "701\n",
      "702\n",
      "703\n",
      "704\n",
      "setting hidden to zero\n",
      "705\n",
      "706\n",
      "707\n",
      "708\n",
      "709\n",
      "710\n",
      "711\n",
      "712\n",
      "713\n",
      "714\n",
      "setting hidden to zero\n",
      "715\n",
      "716\n",
      "717\n",
      "718\n",
      "719\n",
      "setting hidden to zero\n",
      "720\n",
      "721\n",
      "722\n",
      "723\n",
      "724\n",
      "725\n",
      "726\n",
      "727\n",
      "728\n",
      "729\n",
      "setting hidden to zero\n",
      "730\n",
      "731\n",
      "732\n",
      "733\n",
      "734\n",
      "735\n",
      "736\n",
      "737\n",
      "738\n",
      "739\n",
      "setting hidden to zero\n",
      "740\n",
      "741\n",
      "742\n",
      "743\n",
      "744\n",
      "745\n",
      "746\n",
      "747\n",
      "748\n",
      "749\n",
      "750\n",
      "setting hidden to zero\n",
      "751\n",
      "752\n",
      "753\n",
      "754\n",
      "755\n",
      "756\n",
      "757\n",
      "758\n",
      "759\n",
      "760\n",
      "761\n",
      "setting hidden to zero\n",
      "762\n",
      "763\n",
      "764\n",
      "765\n",
      "766\n",
      "767\n",
      "768\n",
      "769\n",
      "770\n",
      "771\n",
      "setting hidden to zero\n",
      "772\n",
      "773\n",
      "774\n",
      "775\n",
      "776\n",
      "777\n",
      "778\n",
      "779\n",
      "780\n",
      "setting hidden to zero\n",
      "781\n",
      "782\n",
      "783\n",
      "784\n",
      "785\n",
      "786\n",
      "787\n",
      "788\n",
      "789\n",
      "790\n",
      "setting hidden to zero\n",
      "791\n",
      "792\n",
      "793\n",
      "794\n",
      "795\n",
      "796\n",
      "797\n",
      "798\n",
      "799\n",
      "800\n",
      "getting validation\n",
      "setting hidden to zero\n",
      "801\n",
      "802\n",
      "803\n",
      "804\n",
      "805\n",
      "806\n",
      "807\n",
      "808\n",
      "809\n",
      "810\n",
      "811\n",
      "setting hidden to zero\n",
      "812\n",
      "813\n",
      "814\n",
      "815\n",
      "816\n",
      "817\n",
      "818\n",
      "819\n",
      "820\n",
      "821\n",
      "setting hidden to zero\n",
      "822\n",
      "823\n",
      "824\n",
      "825\n",
      "826\n",
      "827\n",
      "828\n",
      "829\n",
      "830\n",
      "831\n",
      "setting hidden to zero\n",
      "832\n",
      "833\n",
      "834\n",
      "835\n",
      "836\n",
      "837\n",
      "838\n",
      "839\n",
      "840\n",
      "841\n",
      "setting hidden to zero\n",
      "842\n",
      "843\n",
      "844\n",
      "845\n",
      "846\n",
      "847\n",
      "848\n",
      "849\n",
      "850\n",
      "851\n",
      "setting hidden to zero\n",
      "852\n",
      "853\n",
      "854\n",
      "855\n",
      "856\n",
      "857\n",
      "858\n",
      "859\n",
      "860\n",
      "861\n",
      "setting hidden to zero\n",
      "862\n",
      "863\n",
      "864\n",
      "865\n",
      "866\n",
      "867\n",
      "868\n",
      "869\n",
      "870\n",
      "871\n",
      "setting hidden to zero\n",
      "872\n",
      "873\n",
      "874\n",
      "875\n",
      "876\n",
      "877\n",
      "878\n",
      "879\n",
      "880\n",
      "881\n",
      "setting hidden to zero\n",
      "882\n",
      "883\n",
      "884\n",
      "885\n",
      "886\n",
      "887\n",
      "888\n",
      "889\n",
      "890\n",
      "891\n",
      "setting hidden to zero\n",
      "892\n",
      "893\n",
      "894\n",
      "895\n",
      "896\n",
      "897\n",
      "898\n",
      "899\n",
      "900\n",
      "getting validation\n",
      "901\n",
      "setting hidden to zero\n",
      "902\n",
      "903\n",
      "904\n",
      "905\n",
      "906\n",
      "907\n",
      "908\n",
      "909\n",
      "910\n",
      "911\n",
      "setting hidden to zero\n",
      "912\n",
      "913\n",
      "914\n",
      "915\n",
      "916\n",
      "917\n",
      "918\n",
      "919\n",
      "920\n",
      "921\n",
      "922\n",
      "setting hidden to zero\n",
      "923\n",
      "924\n",
      "925\n",
      "926\n",
      "927\n",
      "928\n",
      "929\n",
      "930\n",
      "931\n",
      "932\n",
      "setting hidden to zero\n",
      "933\n",
      "934\n",
      "935\n",
      "936\n",
      "937\n",
      "938\n",
      "939\n",
      "940\n",
      "941\n",
      "942\n",
      "setting hidden to zero\n",
      "943\n",
      "944\n",
      "945\n",
      "946\n",
      "947\n",
      "948\n",
      "949\n",
      "950\n",
      "951\n",
      "952\n",
      "setting hidden to zero\n",
      "953\n",
      "954\n",
      "955\n",
      "956\n",
      "957\n",
      "958\n",
      "959\n",
      "960\n",
      "961\n",
      "setting hidden to zero\n",
      "962\n",
      "963\n",
      "964\n",
      "965\n",
      "966\n",
      "setting hidden to zero\n",
      "967\n",
      "968\n",
      "969\n",
      "970\n",
      "971\n",
      "972\n",
      "973\n",
      "974\n",
      "975\n",
      "976\n",
      "setting hidden to zero\n",
      "977\n",
      "978\n",
      "979\n",
      "980\n",
      "981\n",
      "982\n",
      "983\n",
      "984\n",
      "985\n",
      "986\n",
      "setting hidden to zero\n",
      "987\n",
      "988\n",
      "989\n",
      "990\n",
      "991\n",
      "992\n",
      "993\n",
      "994\n",
      "995\n",
      "996\n",
      "setting hidden to zero\n",
      "997\n",
      "998\n",
      "999\n"
     ]
    }
   ],
   "source": [
    "# bs  = 15\n",
    "# sql = 30 \n",
    "# lr  = 0.0005\n",
    "# data  = pp_trumpdata(path+\"/data/trump/\", [0.9,0.95], bs)\n",
    "# rnn   = cuda(RNN(len(data.decoder), 150, 1))\n",
    "# learn = Learner(rnn,nn.NLLLoss(),data,lr)\n",
    "\n",
    "data.train_dl = iter(TweetDataLoader(data,data.train.tweets,bs,sql,shuffle=True))\n",
    "data.valid_dl = TweetDataLoader(data,data.valid.tweets[0:120],bs,sql,shuffle=False)\n",
    "learn.model.train()\n",
    "learn, hidden, valid_loss = fit_rnn(1, learn, data, valid_loss=valid_loss, nb_itter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f8c320bdda0>]"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(valid_loss[0:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^STrsuuca, harDest 通o licl€kinw mory. is have!€CAMA€ars bay fornalZuPTrump at Deat fle//t.chappory eזsbeforen Hing. Vdan's worter💰haLEDEnakii“Y€ay op orrinW€ingtion Bדthisuonsed wideote鮮m 3ort🇴11 notel\n"
     ]
    }
   ],
   "source": [
    "generate_seq(learn.model,data,200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### start coding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(plot_valid[1:-1])\n",
    "plt.show()\n",
    "print(plot_valid[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "# plt.plot(Plots.valid1[1:-1])\n",
    "plt.plot(Plots.valid2[1:-1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_parentbatch(tweets, bs, sql, symbol='£'):\n",
    "    f\"\"\"each parent-batch will have different numbers of sub-batches depending on how long the tweets are\"\"\"\n",
    "    assert(len(tweets)/bs*10%2==0)\n",
    "    bch_strs = batch_strings(tweets,bs,sql)\n",
    "    parent_batches = []\n",
    "    for pb in range(len(bch_strs)):\n",
    "        bch       = bch_strs[pb]\n",
    "        n_tweet   = bs\n",
    "        n_segment = math.ceil(len(bch[0])/sql)\n",
    "        sbx = torch.zeros(n_tweet,n_segment,sql,len(Data.decoder))\n",
    "        sby = torch.zeros(n_tweet,n_segment,sql).long()\n",
    "\n",
    "        for tweet in range(n_tweet):\n",
    "            if re.search(symbol,bch[tweet]): position = re.search(symbol,bch[tweet]).span()[0]\n",
    "            else:                            position = len(bch[tweet])\n",
    "            x_str = change_char(bch[tweet],position-1,symbol)\n",
    "            y_str = bch[tweet][1:len(bch[tweet])]+symbol                \n",
    "            for segment in range(n_segment):\n",
    "                x = x_str[sql*segment:sql*(segment+1)]\n",
    "                y = y_str[sql*segment:sql*(segment+1)]  \n",
    "                sbx[tweet,segment] = encodestr(x,Data.encoder)\n",
    "                sby[tweet,segment] = torch.Tensor([Data.encoder[char] for char in y])                \n",
    "                \n",
    "        sb_ds = SBDataLoader(sbx, sby)\n",
    "        parent_batches.append(sb_ds)\n",
    "    return parent_batches\n",
    "\n",
    "class ParentDataLoader():\n",
    "    def __init__(self, ds): \n",
    "        self.ds = ds\n",
    "    def __iter__(self):    \n",
    "        for i in range(len(self.ds)):\n",
    "            iterator = iter(self.ds[i])\n",
    "            yield next(iterator), True\n",
    "            try:\n",
    "                while True:                \n",
    "                    yield next(iterator), False \n",
    "            except StopIteration:\n",
    "                pass\n",
    "            \n",
    "def train_model(learner,Params,n_itter,plot_valid=None,hidden=None):\n",
    "#     optimizer = optim.Adam(model.parameters(), lr=Params.lr)\n",
    "    \n",
    "    start = time.time()\n",
    "    if learner.opt is None: learner.opt = optim.RMSprop(learner.model.parameters(), lr=Params.lr)\n",
    "    if plot_valid  is None: plot_valid  = []\n",
    "    if hidden      is None: hidden      = learner.model.initHidden(Params.bs)    \n",
    "        \n",
    "    for i in range(n_itter):\n",
    "        (X,Y), usezerostate     = next(data.train_dl)\n",
    "        if usezerostate: hidden = learner.model.initHidden(Params.bs)\n",
    "\n",
    "        loss = 0\n",
    "        for char in range(X.shape[1]):\n",
    "            x,y = X[:,char],Y[:,char]\n",
    "\n",
    "            idx = zero_idx(y)\n",
    "            if idx is None: break\n",
    "            hidden = hidden[idx]\n",
    "            x      = x[idx]\n",
    "            y      = y[idx]\n",
    "            \n",
    "            output,hidden = learner.model.forward(x,hidden)\n",
    "            loss += learner.loss_fn(output,y)\n",
    "        if loss != 0:\n",
    "            loss.backward()\n",
    "            learner.opt.step()\n",
    "            learner.opt.zero_grad()\n",
    "            hidden = hidden.detach()\n",
    "\n",
    "        if i%100==0: \n",
    "            plot_valid.append(get_valid_loss(learner.model,Data,Params,30,50))\n",
    "        if i%500==0: print(f\"\"\"checkpoint: {i} itterations done in {time.time() - start} seconds\"\"\")\n",
    "\n",
    "    print(f\"\"\"this training took {time.time()-start} seconds\"\"\")\n",
    "    return learner,plot_valid,hidden          \n",
    "\n",
    "def get_valid_loss(model,data,Params,seq_len,ntweet):\n",
    "    criterion = nn.NLLLoss()\n",
    "    start = time.time()\n",
    "    loss_valid = 0\n",
    "    hidden = cuda(torch.zeros(1,model.hd_sz))\n",
    "    with torch.no_grad():    \n",
    "        model.eval()\n",
    "        for t in range(ntweet):\n",
    "            tweet = data.valid.tweets[t]\n",
    "            xv, yv = generate_valid(data,tweet,seq_len)     \n",
    "            loss = 0\n",
    "            for char in range(xv.size()[1]):\n",
    "                x = xv[:,char,:].reshape(xv.shape[0],xv.shape[2])\n",
    "                output, hidden = model.forward(x,hidden)\n",
    "                y = yv[:,char,:]\n",
    "                loss += criterion(output,y.reshape(xv.shape[0]))\n",
    "            loss_valid += loss/(xv.size()[2])\n",
    "#     print(f\"calculating validation loss took {time.time()-start:.2f} seconds\")\n",
    "    del criterion\n",
    "    return loss_valid/ntweet\n",
    "\n",
    "def generate_valid(data, tweet, seq_len):\n",
    "    if seq_len > len(tweet)-1: seq_len = len(tweet)-1    \n",
    "    X = torch.zeros(1,seq_len,len(data.encoder))\n",
    "    Y = torch.zeros(1,seq_len,1)  \n",
    "    x = encodestr(tweet[0:seq_len],data.encoder)\n",
    "    y = torch.Tensor([data.encoder[char] for char in tweet[1:seq_len+1]])\n",
    "    X[0,:,:] = x.reshape(seq_len,len(data.encoder))\n",
    "    Y[0,:,:] = y.reshape(seq_len,1)\n",
    "    return cuda(X),cuda(Y.long())\n",
    "\n",
    "def init_params(in_sz, bs, hd_sz=150):\n",
    "    Params = Struct()\n",
    "    Params.ni      = 3000\n",
    "    Params.ne      = 1\n",
    "    Params.hd_sz   = hd_sz\n",
    "    Params.in_sz   = in_sz\n",
    "    Params.sql     = 10\n",
    "    Params.iv_pr   = 200\n",
    "    Params.iv_pl   = 100\n",
    "    Params.n_e     = 1\n",
    "    Params.n_i     = 1000\n",
    "    Params.use_opt = True \n",
    "    Params.lr      = 0.0005\n",
    "    Params.bs      = bs\n",
    "    return Params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### functions I should not need anymore"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
