{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device cuda:0\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import time\n",
    "import copy\n",
    "import math \n",
    "import re\n",
    "import json \n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "import pickle\n",
    "import random \n",
    "import pandas as pd\n",
    "\n",
    "from functools import partial \n",
    "\n",
    "cuda_available = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if cuda_available else \"cpu\")\n",
    "print(f'''using device {device}''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.OutputArea.auto_scroll_threshold = 9999;\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.auto_scroll_threshold = 9999;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cuda(input):\n",
    "    if torch.cuda.is_available(): return input.cuda()\n",
    "    return input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/r2/Documents/RNNexp\n"
     ]
    }
   ],
   "source": [
    "path = !pwd\n",
    "path = path[0]\n",
    "print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.read_pickle(path+\"/data/step3_DAT_MT_USDJPY_M1_2018_merged_pickled\") \n",
    "# data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Struct():\n",
    "    pass \n",
    "\n",
    "def load_trumpdata(datapath, pad_tok='£', start_tok='^', end_tok='€'):\n",
    "\n",
    "    van_tws, tws, van_tw_str, tw_str = [],[],'',''\n",
    "    filenames = ['condensed_2018.json', 'condensed_2016.json', 'condensed_2017.json', 'condensed_2015.json']\n",
    "    for fname in filenames:\n",
    "        f = open(datapath+fname,\"r\")\n",
    "        data = f.readline()\n",
    "        f.close()\n",
    "        data_tr = json.loads(data)\n",
    "        for line in range(0,len(data_tr)):\n",
    "            tweet      = data_tr[line][\"text\"].rstrip('\\\\')\n",
    "            van_tw_str = van_tw_str + tweet \n",
    "            van_tws.append(tweet)            \n",
    "    symbols = list(set(van_tw_str))  \n",
    "    assert(pad_tok   not in symbols)\n",
    "    assert(start_tok not in symbols)\n",
    "    assert(end_tok   not in symbols)\n",
    "\n",
    "    for tweet in van_tws:\n",
    "        pad_tweet = start_tok + tweet + end_tok\n",
    "        tw_str    = tw_str + pad_tweet            \n",
    "        tws.append(pad_tweet)        \n",
    "    symbols = [pad_tok, start_tok] + symbols + [end_tok]   \n",
    "    decoder = {idx: symbols[idx] for idx in range(0,len(symbols))}\n",
    "    encoder = {symbols[idx]: idx for idx in range(0,len(symbols))}        \n",
    "    return tws, tw_str, decoder, encoder\n",
    "\n",
    "def pp_trumpdata(filename, prop, bsize=1):\n",
    "    Data, train, valid, test = Struct(), Struct(), Struct(), Struct()        \n",
    "    tweets, tweet_str, Data.decoder, Data.encoder = load_trumpdata(filename)    \n",
    "\n",
    "    train.tweets = tweets[0:round(prop[0]*len(tweets))]\n",
    "    train.tweet_str = tweet_str[0:round(prop[1]*len(tweet_str))]    \n",
    "    valid.tweets = tweets[round(prop[0]*len(tweets)):round(prop[1]*len(tweets))]\n",
    "    valid.tweet_str = tweet_str[round(prop[0]*len(tweet_str)):round(prop[1]*len(tweet_str))]    \n",
    "    test.tweets  = tweets[round(prop[1]*len(tweets)):-1]\n",
    "    test.tweet_str  = tweet_str[round(prop[1]*len(tweet_str)):-1]    \n",
    "\n",
    "    train.batch_str = []\n",
    "    stepsize = round(len(train.tweet_str)/bsize-1)\n",
    "    for i in range(0,bsize):\n",
    "        train.batch_str.append(train.tweet_str[i*stepsize:(i+1)*stepsize])\n",
    "    valid.batch_str = [valid.tweet_str]\n",
    "    \n",
    "    Data.train, Data.valid, Data.test, Data.bsize = train, valid, test, bsize\n",
    "    return Data\n",
    "\n",
    "def save_checkpoint(state, filename='models/checkpoint.pth.tar'):\n",
    "    torch.save(state, filename)\n",
    "\n",
    "def load_checkpoint(filename='models/checkpoint.pth.tar'):\n",
    "    checkpoint = torch.load(filename)    \n",
    "    for item in iter(checkpoint):\n",
    "        print(item)\n",
    "    model = RNN(checkpoint['in_sz'],checkpoint['hd_sz'],checkpoint['out_sz'])\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    #     optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    epoch = checkpoint['epoch']\n",
    "    loss = checkpoint['loss']\n",
    "    return model, epoch, loss    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### encoder/decoders "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encodestr(string, encoder):\n",
    "    x = torch.zeros((len(string),len(encoder)))\n",
    "    x[[idx for idx in range(0,len(string))],[encoder[char] for char in string]] = 1\n",
    "    return x\n",
    "\n",
    "def onehencode(symbol, encoder):\n",
    "    x = torch.zeros(len(encoder),1)\n",
    "    x[encoder[symbol]] = 1.0\n",
    "    return x.t()\n",
    "\n",
    "def encode(string, encoder):\n",
    "    return torch.Tensor([encoder[char] for char in y_str])\n",
    "\n",
    "def onehdecode(X,decoder):\n",
    "    assert(X.shape[-1] == len(decoder))\n",
    "    string = ''\n",
    "    for char in range(X.shape[0]):\n",
    "        val, idx = torch.max(X[char],0)\n",
    "        string += decoder[idx.item()]\n",
    "    print(string)\n",
    "    \n",
    "def ydecode(Y,decoder):\n",
    "    string = ''\n",
    "    for char in range(Y.shape[0]): string += decoder[Y[char].item()]\n",
    "    print(string)\n",
    "\n",
    "def change_char(s, p, r):\n",
    "    return s[:p]+r+s[p+1:] \n",
    "\n",
    "def generate_seq(model,Data,sql,symbol='^'):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        hidden = model.initHidden(1)\n",
    "        result = symbol\n",
    "        for i in range(sql):\n",
    "            x = cuda(onehencode(symbol,Data.encoder))\n",
    "            output, hidden = model.forward(x,hidden)        \n",
    "            hidden = hidden.detach()\n",
    "            \n",
    "            prob     = np.exp(output[0].cpu().numpy())\n",
    "            cum_prob = np.cumsum(prob)\n",
    "            idx      = np.where(cum_prob - random.random() > 0)[0][0]\n",
    "            symbol   = Data.decoder[idx]\n",
    "            result  += symbol\n",
    "    model.train()\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## my RNN module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNoriginal(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNNoriginal,self).__init__()\n",
    "        self.hd_sz  = hidden_size\n",
    "        self.in_sz  = input_size\n",
    "        self.out_sz = output_size\n",
    "        \n",
    "        self.h1  = nn.Linear(input_size + hidden_size, hidden_size)               \n",
    "        self.o1   = nn.Linear(input_size + hidden_size, input_size)\n",
    "\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "        \n",
    "    def forward(self, input, hidden):\n",
    "        combined = torch.cat((input, hidden), 1)    \n",
    "        \n",
    "        hidden   = self.h1(combined)\n",
    "        hidden   = torch.tanh(hidden)\n",
    "        \n",
    "        output   = self.o1(combined)\n",
    "        output   = self.softmax(output)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self,bs):\n",
    "        return cuda(torch.zeros(bs,self.hd_sz))\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNN,self).__init__()\n",
    "        self.hd_sz  = hidden_size\n",
    "        self.in_sz  = input_size\n",
    "        self.out_sz = output_size\n",
    "        \n",
    "        combined = input_size+hidden_size\n",
    "        \n",
    "        self.h1      = nn.Linear(combined, hidden_size)               \n",
    "\n",
    "        self.o1      = nn.Linear(combined, combined)\n",
    "        self.relu    = nn.ReLU(combined)\n",
    "\n",
    "        self.o2      = nn.Linear(combined, input_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "        \n",
    "    def forward(self, input, hidden):\n",
    "        combined = torch.cat((input, hidden), 1)    \n",
    "        \n",
    "        hidden   = self.h1(combined)\n",
    "        hidden   = torch.tanh(hidden)\n",
    "        \n",
    "        output   = self.o1(combined)\n",
    "        output   = self.relu(output)\n",
    "        \n",
    "        output   = self.o2(output)\n",
    "        output   = self.softmax(output)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self,bs):\n",
    "        return cuda(torch.zeros(bs,self.hd_sz))\n",
    "\n",
    "def weights_init_uniform(m):\n",
    "    classname = m.__class__.__name__\n",
    "    # for every Linear layer in a model..\n",
    "    if classname.find('Linear') != -1:\n",
    "        # apply a uniform distribution to the weights and a bias=0\n",
    "        m.weight.data.uniform_(0.0, 1.0)\n",
    "        m.bias.data.fill_(0)\n",
    "\n",
    "def weights_init_xavier(m):\n",
    "    classname = m.__class__.__name__\n",
    "    # for every Linear layer in a model..\n",
    "    if classname.find('Linear') != -1:\n",
    "        torch.nn.init.xavier_uniform_(m.weight)\n",
    "        m.bias.data.fill_(0.01)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataLoaders, Itterators, DataSets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad(str_list,sql=1,token='£'):\n",
    "    f\"\"\"pad all strings in a list to max_len\"\"\"\n",
    "    max_len = math.ceil(len(max(str_list, key=len))/sql)*sql\n",
    "    for idx, row in enumerate(str_list):        \n",
    "        str_list[idx] = row + token*(max_len-len(row))\n",
    "    if len(str_list) == 1: return str_list[0]\n",
    "    return str_list\n",
    "\n",
    "def mk_tweetbatch(tweets,encoder,bs,sql,symbol='£'):\n",
    "    assert(math.floor(len(tweets)/bs)==len(tweets)/bs)\n",
    "    bch       = batch_strings(tweets,bs,sql)[0]\n",
    "    assert(math.floor(len(bch[0])/sql)==len(bch[0])/sql)            \n",
    "    n_segment = int(len(bch[0])/sql)\n",
    "    sbx       = torch.zeros(bs,n_segment,sql,len(encoder))\n",
    "    sby       = torch.zeros(bs,n_segment,sql).long()\n",
    "    for tweet in range(bs):\n",
    "        \"\"\"for target we don't use first char, compensate with one padded char\"\"\"\n",
    "        y_str = bch[tweet][1:len(bch[tweet])]+symbol      \n",
    "        \n",
    "        chng_pos = len(bch[tweet])\n",
    "        \"\"\"if we find padded char, we know that tweet ended, remove last char of tweet\"\"\"        \n",
    "        if re.search(symbol,bch[tweet]): chng_pos = re.search(symbol,bch[tweet]).span()[0]       \n",
    "        x_str = change_char(bch[tweet],chng_pos-1,symbol)     \n",
    "        \n",
    "        for segment in range(n_segment):\n",
    "            x = x_str[sql*segment:sql*(segment+1)]\n",
    "            y = y_str[sql*segment:sql*(segment+1)]  \n",
    "            sbx[tweet,segment] = encodestr(x,encoder)\n",
    "            sby[tweet,segment] = torch.Tensor([encoder[char] for char in y])                    \n",
    "    return sbx,sby\n",
    "\n",
    "class TweetDataLoader():\n",
    "    def __init__(self,data,tweets,bs,sql,shuffle=False):    \n",
    "#         assert(math.floor(len(tweets)/bs)==len(tweets)/bs)\n",
    "        self.tweets  = tweets\n",
    "        self.bs      = bs         \n",
    "        self.sql     = sql\n",
    "        self.encoder = data.encoder\n",
    "        self.decoder = data.decoder\n",
    "        self.i       = -1\n",
    "        self.ii      = 0 \n",
    "        self.shuffle = shuffle        \n",
    "        \n",
    "    def reset(self):\n",
    "        if self.shuffle: random.shuffle(self.tweets)\n",
    "        self.i  = -1\n",
    "        self.ii = 0\n",
    "        \n",
    "    def nb_itters(self):\n",
    "        return self.ii \n",
    "    \n",
    "    def __iter__(self):  \n",
    "        self.reset()\n",
    "        while True:\n",
    "            self.i += 1\n",
    "            twt      = self.tweets[self.i*self.bs:(self.i+1)*self.bs]\n",
    "            sbx,sby  = mk_tweetbatch(twt,self.encoder,self.bs,self.sql)\n",
    "            sbloader = iter(SBDataLoader(sbx,sby))            \n",
    "            try:\n",
    "                while True:                \n",
    "                    self.ii+=1                    \n",
    "                    yield next(sbloader) \n",
    "            except StopIteration:\n",
    "                self.ii-=1\n",
    "                pass            \n",
    "            if self.i==round(len(self.tweets)/self.bs)-1: \n",
    "                self.reset()\n",
    "                break\n",
    "\n",
    "class SBDataLoader():\n",
    "    def __init__(self, sbx, sby): \n",
    "        self.sbx, self.sby = sbx, sby\n",
    "    def __iter__(self):\n",
    "        for j in range(self.sbx.shape[1]): yield cuda(self.sbx[:,j]), cuda(self.sby[:,j])\n",
    "\n",
    "def batch_strings(tweets,bs,sql=1):\n",
    "    f\"\"\"creates a list of batchsize-list of strings of same length and sort each batch with longest string first.\"\"\"    \n",
    "    \"\"\"NOT SURE ABOUT THIS OFFSET, BUT THE PREVIOUS CODE ALWAYS MADE A 0\"\"\"\n",
    "    offset = -1*((len(tweets)/bs)*10%2!=0)    \n",
    "#     offset = -1*((math.floor(len(tweets)/bs)==len(tweets)/bs)==0)    \n",
    "    bch_strs = [] \n",
    "    for i in range(round(len(tweets)/bs)+offset):\n",
    "        strings = tweets[i*bs:(i+1)*bs]\n",
    "        strings.sort(key=len,reverse=True)\n",
    "        pad_strings = pad(strings,sql)\n",
    "        bch_strs.append(pad_strings)\n",
    "    return bch_strs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### building FastAI classes to be used with callbacks in future\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Learner():\n",
    "    def __init__(self, model, loss_fn, data, lr):\n",
    "        opt = optim.RMSprop(model.parameters(), lr)\n",
    "        model.train()\n",
    "        assert(model is not None)\n",
    "        assert(loss_fn is not None)\n",
    "        assert(data is not None)\n",
    "        self.model   = model\n",
    "        self.opt     = opt\n",
    "        self.loss_fn = loss_fn\n",
    "        self.data    = data \n",
    "        self._lr     = opt.param_groups[0]['lr']\n",
    "        \n",
    "    @property\n",
    "    def lr(self):\n",
    "        return self._lr\n",
    "    \n",
    "    @lr.setter\n",
    "    def lr(self,lr):\n",
    "        self._lr = lr\n",
    "        for param_group in self.opt.param_groups:\n",
    "            param_group['lr'] = lr        \n",
    "    \n",
    "class Callback():\n",
    "    def begin_fit(self,learn):\n",
    "        self.learn = learn\n",
    "        return True\n",
    "    def after_fit(self): return True\n",
    "    def begin_epoch(self,epoch):\n",
    "        self.epoch=epoch\n",
    "        return True\n",
    "    def begin_validate(self): return True\n",
    "    def after_epoch(self): return True \n",
    "    def begin_batch(self,xb,yb):\n",
    "        self.xb,self.yb = xb,yb\n",
    "        return True\n",
    "    def after_loss(self,loss):\n",
    "        self.loss=loss\n",
    "        return True\n",
    "    def after_backward(self): return True\n",
    "    def after_step(self): return True\n",
    "\n",
    "class TrainEvalCallback(Callback):\n",
    "    def begin_fit(self):\n",
    "        self.run.n_epochs=0.\n",
    "        self.run.n_iter=0\n",
    "    \n",
    "    def after_batch(self):\n",
    "        if not self.in_train: return\n",
    "        self.run.n_epochs += 1./self.iters\n",
    "        self.run.n_iter   += 1\n",
    "        \n",
    "    def begin_epoch(self):\n",
    "        self.run.n_epochs=self.epoch\n",
    "        self.model.train()\n",
    "        self.run.in_train=True\n",
    "\n",
    "    def begin_validate(self):\n",
    "        self.model.eval()\n",
    "        self.run.in_train=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_rnn(learn, data, epoches, valid_loss=[], itters=math.inf, cb=None):\n",
    "    for e in range(epoches):\n",
    "        hidden = learn.model.initHidden(15)\n",
    "        for xb, yb in iter(data.train_dl):   \n",
    "            output, hidden, loss = rnn_forward(learn,hidden,xb,yb)\n",
    "            if loss != 0:\n",
    "                loss.backward()\n",
    "                learn.opt.step()\n",
    "                learn.opt.zero_grad()\n",
    "            if (data.train_dl.nb_itters()%100==0): valid_loss.append(get_valid(learn,data,itters=30))  \n",
    "            if data.train_dl.nb_itters() == itters: break\n",
    "    return learn, hidden, valid_loss\n",
    "\n",
    "def rnn_forward(learn,hidden,xb,yb):\n",
    "    if xb[0,0,1].item() == 1: hidden = learn.model.initHidden(xb.shape[0])                   \n",
    "    loss = 0 \n",
    "    for char in range(xb.shape[1]):\n",
    "        x,y = xb[:,char],yb[:,char]\n",
    "\n",
    "        x,y,hidden = unpad_rnn(x,y,hidden)\n",
    "        if x is None: break\n",
    "        \n",
    "        output,hidden = learn.model.forward(x,hidden)\n",
    "        loss += learn.loss_fn(output,y)                \n",
    "\n",
    "    if loss == 0: return None, hidden.detach(),loss \n",
    "    return output,hidden.detach(),loss/(char+1)\n",
    "\n",
    "def unpad_rnn(x,y,hidden):\n",
    "    idx = (y != 0).nonzero()\n",
    "    if idx.shape[0] < 2: return None,y,hidden\n",
    "    else: idx = idx.squeeze()\n",
    "    return x[idx],y[idx],hidden[idx]\n",
    "\n",
    "def get_valid(learn,data,itters=30):\n",
    "    print(f\"\"\"getting validation\"\"\")    \n",
    "    learn.model.eval()\n",
    "    tot_loss = 0 \n",
    "    with torch.no_grad():\n",
    "        hidden = learn.model.initHidden(15)\n",
    "        for xb,yb in iter(data.valid_dl): \n",
    "            output, hidden, loss = rnn_forward(learn,hidden,xb,yb)  \n",
    "            if loss != 0: tot_loss += loss.item()/xb.shape[0]\n",
    "            if data.valid_dl.nb_itters() == itters: \n",
    "                return tot_loss/data.valid_dl.nb_itters()\n",
    "        \n",
    "    return tot_loss/data.valid_dl.nb_itters()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### start coding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs  = 15\n",
    "sql = 30 \n",
    "\n",
    "data          = pp_trumpdata(path+\"/data/trump/\", [0.9,0.95], bs)\n",
    "data.train_dl = TweetDataLoader(data,data.train.tweets,bs,sql,shuffle=True)\n",
    "data.valid_dl = TweetDataLoader(data,data.valid.tweets,bs,sql,shuffle=False)\n",
    "\n",
    "learn = Learner(model=cuda(RNN(len(data.decoder), 150, 1)),loss_fn=nn.NLLLoss(),data=data,lr=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting validation\n",
      "getting validation\n",
      "getting validation\n",
      "getting validation\n",
      "getting validation\n",
      "getting validation\n",
      "getting validation\n",
      "getting validation\n",
      "getting validation\n",
      "getting validation\n",
      "took 29.734977960586548 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "learn, hidden, valid_loss = fit_rnn(learn, data, epoches=1, valid_loss=valid_loss, itters=1000)\n",
    "print(f\"\"\"took {time.time()-start} seconds\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0974767257107629\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(valid_loss[0:-1])\n",
    "print(valid_loss[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^Thany, no inferty!€I\n",
      "#Emefull2016 https://t.co/rtL6SJ0pX€€\"€mW erent Trump, nots and prime candluss that the begages of 6 handsedful hout and dids and very salworking at, hin by exce, the Lennor of o \n"
     ]
    }
   ],
   "source": [
    "generate_seq(learn.model,data,200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### functions I should not need anymore"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
