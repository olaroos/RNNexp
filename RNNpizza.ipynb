{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device cuda:0\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import time\n",
    "import copy\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "cuda_available = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if cuda_available else \"cpu\")\n",
    "print(f'''using device {device}''')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import numpy as np\n",
    "import pickle\n",
    "import random \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.OutputArea.auto_scroll_threshold = 9999;\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.auto_scroll_threshold = 9999;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def usecuda(input):\n",
    "    if torch.cuda.is_available(): return input.cuda()\n",
    "    return input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/r2/Documents/RNNexp\n"
     ]
    }
   ],
   "source": [
    "path = !pwd\n",
    "path = path[0]\n",
    "print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.read_pickle(path+\"/data/step3_DAT_MT_USDJPY_M1_2018_merged_pickled\") \n",
    "# data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Struct():\n",
    "    pass \n",
    "\n",
    "def load_trumpdata(datapath):\n",
    "    import json \n",
    "    tweets, tweet_str = [], ''\n",
    "    filenames = ['condensed_2018.json', 'condensed_2016.json', 'condensed_2017.json', 'condensed_2018.json']\n",
    "    for fname in filenames:\n",
    "        f = open(datapath+fname,\"r\")\n",
    "        print(datapath+fname)\n",
    "        data = f.readline()\n",
    "        print(data)\n",
    "        f.close()\n",
    "        data_tr = json.loads(data)\n",
    "        for line in range(0,len(data_tr)):\n",
    "            tweet = data_tr[line][\"text\"].rstrip('\\\\') + '€'\n",
    "            tweets.append(tweet)\n",
    "            tweet_str = tweet_str + tweet            \n",
    "    symbols = list(set(tweet_str))\n",
    "    decoder = {idx: symbols[idx] for idx in range(0,len(symbols))}\n",
    "    encoder = {symbols[idx]: idx for idx in range(0,len(symbols))}        \n",
    "    return tweets, tweet_str, decoder, encoder\n",
    "\n",
    "def pp_trumpdata(tweets,tweet_str,prop):\n",
    "    data_train, data_valid, data_test = Struct(), Struct(), Struct()\n",
    "    data_train.tweets = tweets[0:round(prop[0]*len(tweets))]\n",
    "    data_valid.tweets = tweets[round(prop[0]*len(tweets)):round(prop[1]*len(tweets))]\n",
    "    data_test.tweets  = tweets[round(prop[1]*len(tweets)):-1]\n",
    "    data_train.tweet_str = tweet_str[0:round(prop[1]*len(tweet_str))]\n",
    "    data_valid.tweet_str = tweet_str[round(prop[0]*len(tweet_str)):round(prop[1]*len(tweet_str))]\n",
    "    data_test.tweet_str  = tweet_str[round(prop[1]*len(tweet_str)):-1]    \n",
    "    return data_train, data_valid, data_test\n",
    "\n",
    "def onehencode(symbol, encoder):\n",
    "    x = torch.zeros(len(encoder),1)\n",
    "    x[encoder[symbol]] = 1\n",
    "    return usecuda(x.t())\n",
    "\n",
    "def generate_input(e, seq_len, tweet_str):\n",
    "    Xstr = tweet_str[e:e+seq_len]\n",
    "    Ystr = tweet_str[e+1:e+seq_len+1]\n",
    "    X, Y = torch.zeros(seq_len,1,len(encoder)),torch.zeros(seq_len,1)\n",
    "    for i in range(len(Xstr)):\n",
    "        x = onehencode(Xstr[i], encoder)\n",
    "        X[i][:] = x\n",
    "        Y[i] = encoder[Ystr[i]]\n",
    "    return usecuda(X),usecuda(Y.long())\n",
    "\n",
    "def train(X,Y,hidden,lr,use_opt=False):\n",
    "    \n",
    "    if use_opt: optimizer.zero_grad()\n",
    "    else: rnn.zero_grad()\n",
    "    \n",
    "    loss = 0\n",
    "    for i in range(X.size()[0]):\n",
    "        output, hidden = rnn.forward(X[i],hidden)\n",
    "        l = criterion(output,Y[i])\n",
    "        loss += l\n",
    "\n",
    "\n",
    "    loss.backward()\n",
    "    \n",
    "    # update parameters\n",
    "    if use_opt: optimizer.step()\n",
    "    else:\n",
    "        for p in rnn.parameters():\n",
    "            p.data.add_(-lr, p.grad.data)\n",
    "\n",
    "    return loss / X.size()[0], hidden.detach()\n",
    "\n",
    "def generate_seq(model, hidden, symbol, seq_len, m, seed):\n",
    "    with torch.no_grad():\n",
    "        result_str = symbol\n",
    "        for i in range(seq_len):\n",
    "            x = onehencode(symbol,encoder)\n",
    "            output, new_hidden = model.forward(x,hidden)\n",
    "        \n",
    "            hidden = new_hidden.detach()\n",
    "            prob = np.exp(output.detach().data.cpu().numpy())\n",
    "            cum_prob = np.cumsum(prob)\n",
    "\n",
    "            a = random.random()\n",
    "            idx = np.where(cum_prob - a > 0)[0][0]\n",
    "            symbol = decoder[idx]\n",
    "            result_str += symbol\n",
    "\n",
    "        return result_str\n",
    "    \n",
    "def save_checkpoint(state, filename='models/checkpoint.pth.tar'):\n",
    "    torch.save(state, filename)\n",
    "\n",
    "def load_checkpoint(filename='models/checkpoint.pth.tar'):\n",
    "    checkpoint = torch.load(filename)    \n",
    "    for item in iter(checkpoint):\n",
    "        print(item)\n",
    "    model = RNN(checkpoint['in_sz'],checkpoint['hd_sz'],checkpoint['out_sz'])\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    #     optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    epoch = checkpoint['epoch']\n",
    "    loss = checkpoint['loss']\n",
    "    return model, epoch, loss    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## my RNN module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNN,self).__init__()\n",
    "        self.hd_sz  = hidden_size\n",
    "        self.in_sz  = input_size\n",
    "        self.out_sz = output_size\n",
    "        \n",
    "        self.h1 = nn.Linear(input_size + hidden_size, hidden_size)        \n",
    "        self.o1 = nn.Linear(input_size + hidden_size, input_size)\n",
    "        \n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "        \n",
    "    def forward(self, input, hidden):\n",
    "        combined = torch.cat((input, hidden), 1)\n",
    "        hidden = torch.tanh(self.h1(combined))\n",
    "        output = self.o1(combined)\n",
    "        output = self.softmax(output)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(hidden_layers[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tweets, tweet_str, decoder, encoder = load_trumpdata(path+\"/data/trump/\")\n",
    "data_train, data_valid, data_test   = pp_trumpdata(tweets, tweet_str, [0.9,0.95])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2059339"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_train.tweet_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "m, hsize, seq_len = len(encoder), 150, 30\n",
    "hidden = usecuda(torch.zeros(1,hsize))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data?\n",
    "# rnn, epoch, loss = load_checkpoint(filename='models/checkpoint.pth.tar')\n",
    "# usecuda(rnn)\n",
    "# no?\n",
    "rnn = usecuda(RNN(m,hsize,m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_every, plot_every = 500, 50\n",
    "loss_plots = Struct()\n",
    "loss_plots.train, loss_plots.valid = [], []\n",
    "\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "lr = 0.0005\n",
    "optimizer = optim.RMSprop(rnn.parameters(), lr=lr)\n",
    "\n",
    "itters, epochs, use_opt = round(len(data_train.tweet_str)/seq_len), 1, True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for param_group in optimizer.param_groups:\n",
    "#         param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_valid_loss(data_valid, seq_len):\n",
    "    start = time.time()\n",
    "    i, e, itters = 0, 0, 1000 \n",
    "    loss_valid = 0\n",
    "    hidden = usecuda(torch.zeros(1,rnn.hd_sz))\n",
    "    while i < itters:\n",
    "        Xvalid, Yvalid = generate_input(e,seq_len,data_valid.tweet_str)\n",
    "        loss, hidden   = train(Xvalid,Yvalid,hidden,base_lr,use_opt) \n",
    "        loss_valid += loss\n",
    "        i += 1\n",
    "        e += seq_len + 1\n",
    "    print(f\"calculating validation loss took {time.time()-start:.2f} seconds\")\n",
    "    return loss_valid/itters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_loss is 0.009296826086938381\n",
      "T t sn t:nRhwu,rsSNbtats olrlto . mB’w o ot. tp btrasob r hdreSyte’s  uo Wne ou sd ber  toswdI ae  pn\n",
      "training_loss is 0.30157381296157837\n",
      "Tha ue lemTr.;!Ist sh Pr elW nn   ehn nSat  oa Ah  uevepr aei usthedeh’estehdrBst  osene  ndm m earT \n",
      "training_loss is 0.3036665916442871\n",
      "T,oonati oo tio sedaapFnto eo esrlyrat ao ssooledongfeI tervy terueas en thaw wo. th taikl Cnf eo rhs\n",
      "training_loss is 0.28092849254608154\n",
      "Tnotheg ioinA thCrtipesu pent..”.MT.re datous,n afei  ro’t SruEy w chedee tesn iee nnma eerwihd Ws ba\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "loss_train, hidden = 0, usecuda(torch.zeros(1,rnn.hd_sz))\n",
    "for epoch in range(epochs):\n",
    "    e = 0 \n",
    "    i = 0\n",
    "    while i < itters:\n",
    "        Xtrain,Ytrain = generate_input(e,seq_len,data_train.tweet_str)  \n",
    "        loss, hidden  = train(Xtrain,Ytrain,hidden,lr,use_opt)\n",
    "        loss_train += loss  \n",
    "        if i==1:\n",
    "            loss_plots.train.append(loss_train)\n",
    "        if i%print_every == 0:\n",
    "            print(f\"\"\"training_loss is {loss_train/print_every}\"\"\")\n",
    "            print(generate_seq(rnn,hidden,'T',100,m,42))\n",
    "        if i%plot_every == 0:\n",
    "            loss_plots.train.append(loss_train/plot_every)\n",
    "#             loss_plots.valid.append(get_validloss(data_valid))\n",
    "            loss_train = 0  \n",
    "        e += seq_len + 1\n",
    "        i += 1\n",
    "            \n",
    "    print(f\"\"\"\\n epoch {epoch} took {time.time() - start:.2f} seconds\"\"\")       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(loss_plots.train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_checkpoint({\n",
    "            'epoch': epoch,\n",
    "            'arch': \"1_RNN\",\n",
    "            'state_dict': rnn.state_dict(),\n",
    "            'hd_sz': rnn.hd_sz,\n",
    "            'in_sz': rnn.in_sz,\n",
    "            'out_sz': rnn.out_sz,\n",
    "            'loss': loss,\n",
    "            'best_prec1': None,\n",
    "            'optimizer' : None,\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn2, epoch, loss = load_checkpoint(filename='models/checkpoint.pth.tar')\n",
    "rnn2.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(generate_seq(rnn2, torch.zeros(1,hsize).cuda(),'T',100,m,42))\n",
    "print(generate_seq(rnn, torch.zeros(1,hsize).cuda(),'T',100,m,42))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### build RNN network with LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNN,self).__init__()\n",
    "        self.hidden_sizes = hidden_size\n",
    "        self.in_size      = input_size\n",
    "        self.out_size     = output_size\n",
    "        \n",
    "        self.h1 = nn.Linear(input_size + hidden_size, hidden_size)        \n",
    "        self.o1 = nn.Linear(input_size + hidden_size, input_size)\n",
    "        \n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "        \n",
    "    def forward(self, input, hidden):\n",
    "        combined = torch.cat((input, hidden), 1)\n",
    "        hidden = torch.tanh(self.h1(combined))\n",
    "        output = self.o1(combined)\n",
    "        output = self.softmax(output)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(hidden_layers[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### cut input into seq length bits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[['Open','High','Low','Close']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff = 0.2\n",
    "set_train = data[0:round(len(data)*cutoff)]\n",
    "set_test  = data[round(len(data)*cutoff):-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sz = set_train.shape[1]\n",
    "hidden_sz = 100\n",
    "output_sz = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = RNN(input_sz, hidden_sz, output_sz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for index, row in set_train.iterrows():\n",
    "#     print(np.array(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.005\n",
    "\n",
    "def train(X,Y)\n",
    "    hidden = rnn.initHidden()\n",
    "    \n",
    "    rnn.zero_grad()\n",
    "    \n",
    "    for i in range(X.size()[0]):\n",
    "        output, hidden = rnn(X[i], hidden)\n",
    "        \n",
    "    loss = criterion(output, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
