{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device cuda:0\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import time\n",
    "import copy\n",
    "import math \n",
    "import re\n",
    "import json \n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "import pickle\n",
    "import random \n",
    "import pandas as pd\n",
    "\n",
    "cuda_available = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if cuda_available else \"cpu\")\n",
    "print(f'''using device {device}''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.OutputArea.auto_scroll_threshold = 9999;\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.auto_scroll_threshold = 9999;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cuda(input):\n",
    "    if torch.cuda.is_available(): return input.cuda()\n",
    "    return input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/r2/Documents/RNNexp\n"
     ]
    }
   ],
   "source": [
    "path = !pwd\n",
    "path = path[0]\n",
    "print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.read_pickle(path+\"/data/step3_DAT_MT_USDJPY_M1_2018_merged_pickled\") \n",
    "# data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Struct():\n",
    "    pass \n",
    "\n",
    "def load_trumpdata(datapath, pad_tok='Â£', start_tok='^', end_tok='â‚¬'):\n",
    "\n",
    "    van_tws, tws, van_tw_str, tw_str = [],[],'',''\n",
    "    filenames = ['condensed_2018.json', 'condensed_2016.json', 'condensed_2017.json', 'condensed_2018.json']\n",
    "    for fname in filenames:\n",
    "        f = open(datapath+fname,\"r\")\n",
    "        data = f.readline()\n",
    "        f.close()\n",
    "        data_tr = json.loads(data)\n",
    "        for line in range(0,len(data_tr)):\n",
    "            tweet      = data_tr[line][\"text\"].rstrip('\\\\')\n",
    "            van_tw_str = van_tw_str + tweet \n",
    "            van_tws.append(tweet)            \n",
    "    symbols = list(set(van_tw_str))  \n",
    "    assert(pad_tok   not in symbols)\n",
    "    assert(start_tok not in symbols)\n",
    "    assert(end_tok   not in symbols)\n",
    "\n",
    "    for tweet in van_tws:\n",
    "        pad_tweet = start_tok + tweet + end_tok\n",
    "        tw_str    = tw_str + pad_tweet            \n",
    "        tws.append(pad_tweet)        \n",
    "    symbols = [pad_tok] + symbols + [start_tok, end_tok]   \n",
    "    decoder = {idx: symbols[idx] for idx in range(0,len(symbols))}\n",
    "    encoder = {symbols[idx]: idx for idx in range(0,len(symbols))}        \n",
    "    return tws, tw_str, decoder, encoder\n",
    "\n",
    "def pp_trumpdata(filename, prop, bsize=1):\n",
    "    Data, train, valid, test = Struct(), Struct(), Struct(), Struct()        \n",
    "    tweets, tweet_str, Data.decoder, Data.encoder = load_trumpdata(filename)    \n",
    "\n",
    "    train.tweets = tweets[0:round(prop[0]*len(tweets))]\n",
    "    train.tweet_str = tweet_str[0:round(prop[1]*len(tweet_str))]    \n",
    "    valid.tweets = tweets[round(prop[0]*len(tweets)):round(prop[1]*len(tweets))]\n",
    "    valid.tweet_str = tweet_str[round(prop[0]*len(tweet_str)):round(prop[1]*len(tweet_str))]    \n",
    "    test.tweets  = tweets[round(prop[1]*len(tweets)):-1]\n",
    "    test.tweet_str  = tweet_str[round(prop[1]*len(tweet_str)):-1]    \n",
    "\n",
    "    train.batch_str = []\n",
    "    stepsize = round(len(train.tweet_str)/bsize-1)\n",
    "    for i in range(0,bsize):\n",
    "        train.batch_str.append(train.tweet_str[i*stepsize:(i+1)*stepsize])\n",
    "    valid.batch_str = [valid.tweet_str]\n",
    "    \n",
    "    Data.train, Data.valid, Data.test, Data.bsize = train, valid, test, bsize\n",
    "    return Data\n",
    "\n",
    "def save_checkpoint(state, filename='models/checkpoint.pth.tar'):\n",
    "    torch.save(state, filename)\n",
    "\n",
    "def load_checkpoint(filename='models/checkpoint.pth.tar'):\n",
    "    checkpoint = torch.load(filename)    \n",
    "    for item in iter(checkpoint):\n",
    "        print(item)\n",
    "    model = RNN(checkpoint['in_sz'],checkpoint['hd_sz'],checkpoint['out_sz'])\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    #     optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    epoch = checkpoint['epoch']\n",
    "    loss = checkpoint['loss']\n",
    "    return model, epoch, loss    \n",
    "\n",
    "def get_valid_loss(model,Data,Params,seq_len,ntweet):\n",
    "    criterion = nn.NLLLoss()\n",
    "    start = time.time()\n",
    "    loss_valid = 0\n",
    "    hidden = cuda(torch.zeros(1,model.hd_sz))\n",
    "    with torch.no_grad():    \n",
    "        model.eval()\n",
    "        for t in range(ntweet):\n",
    "            tweet = Data.valid.tweets[t]\n",
    "            xv, yv = generate_valid(Data,tweet,seq_len)     \n",
    "            loss = 0\n",
    "            for char in range(xv.size()[1]):\n",
    "                x = xv[:,char,:].reshape(xv.shape[0],xv.shape[2])\n",
    "                output, hidden = model.forward(x,hidden)\n",
    "                y = yv[:,char,:]\n",
    "                loss += criterion(output,y.reshape(xv.shape[0]))\n",
    "            loss_valid += loss/(xv.size()[2])\n",
    "#     print(f\"calculating validation loss took {time.time()-start:.2f} seconds\")\n",
    "    del criterion\n",
    "    return loss_valid/ntweet\n",
    "\n",
    "def generate_valid(Data, tweet, seq_len):\n",
    "    if seq_len > len(tweet)-1: seq_len = len(tweet)-1    \n",
    "    X = torch.zeros(1,seq_len,len(Data.encoder))\n",
    "    Y = torch.zeros(1,seq_len,1)  \n",
    "    x = encodestr(tweet[0:seq_len],Data.encoder)\n",
    "    y = torch.Tensor([Data.encoder[char] for char in tweet[1:seq_len+1]])\n",
    "    X[0,:,:] = x.reshape(seq_len,len(Data.encoder))\n",
    "    Y[0,:,:] = y.reshape(seq_len,1)\n",
    "    return cuda(X),cuda(Y.long())\n",
    "\n",
    "def init_params(in_sz, bs, hd_sz=150):\n",
    "    Params = Struct()\n",
    "    Params.ni      = 3000\n",
    "    Params.ne      = 1\n",
    "    Params.hd_sz   = hd_sz\n",
    "    Params.in_sz   = in_sz\n",
    "    Params.sql     = 10\n",
    "    Params.iv_pr   = 200\n",
    "    Params.iv_pl   = 100\n",
    "    Params.n_e     = 1\n",
    "    Params.n_i     = 1000\n",
    "    Params.use_opt = True \n",
    "    Params.lr      = 0.0005\n",
    "    Params.bs      = bs\n",
    "    return Params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### encoder/decoders "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encodestr(string, encoder):\n",
    "    x = torch.zeros((len(string),len(encoder)))\n",
    "    x[[idx for idx in range(0,len(string))],[encoder[char] for char in string]] = 1\n",
    "    return x\n",
    "\n",
    "def onehencode(symbol, encoder):\n",
    "    x = torch.zeros(len(encoder),1)\n",
    "    x[encoder[symbol]] = 1.0\n",
    "    return x.t()\n",
    "\n",
    "def encode(string, encoder):\n",
    "    return torch.Tensor([encoder[char] for char in y_str])\n",
    "\n",
    "def onehdecode(X,decoder):\n",
    "    string = ''\n",
    "    for char in range(X.shape[0]):\n",
    "        val, idx = torch.max(X[char],0)\n",
    "        string += decoder[idx.item()]\n",
    "    print(string)\n",
    "    \n",
    "def ydecode(Y,decoder):\n",
    "    string = ''\n",
    "    for char in range(Y.shape[0]): string += decoder[Y[char].item()]\n",
    "    print(string)\n",
    "\n",
    "def change_char(s, p, r):\n",
    "    return s[:p]+r+s[p+1:] \n",
    "\n",
    "def generate_seq(model,Data,sql,symbol='^'):\n",
    "    with torch.no_grad():\n",
    "        hidden = model.initHidden(1)\n",
    "        result = symbol\n",
    "        for i in range(sql):\n",
    "            x = cuda(onehencode(symbol,Data.encoder))\n",
    "            output, hidden = model.forward(x,hidden)        \n",
    "            hidden = hidden.detach()\n",
    "            \n",
    "            prob     = np.exp(output[0].cpu().numpy())\n",
    "            cum_prob = np.cumsum(prob)\n",
    "            idx      = np.where(cum_prob - random.random() > 0)[0][0]\n",
    "            symbol   = Data.decoder[idx]\n",
    "            result  += symbol\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## my RNN module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNoriginal(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNNoriginal,self).__init__()\n",
    "        self.hd_sz  = hidden_size\n",
    "        self.in_sz  = input_size\n",
    "        self.out_sz = output_size\n",
    "        \n",
    "        self.h1  = nn.Linear(input_size + hidden_size, hidden_size)               \n",
    "        self.o1   = nn.Linear(input_size + hidden_size, input_size)\n",
    "\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "        \n",
    "    def forward(self, input, hidden):\n",
    "        combined = torch.cat((input, hidden), 1)    \n",
    "        \n",
    "        hidden   = self.h1(combined)\n",
    "        hidden   = torch.tanh(hidden)\n",
    "        \n",
    "        output   = self.o1(combined)\n",
    "        output   = self.softmax(output)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self,bs):\n",
    "        return cuda(torch.zeros(bs,self.hd_sz))\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNN,self).__init__()\n",
    "        self.hd_sz  = hidden_size\n",
    "        self.in_sz  = input_size\n",
    "        self.out_sz = output_size\n",
    "        \n",
    "        combined = input_size+hidden_size\n",
    "        \n",
    "        self.h1      = nn.Linear(combined, hidden_size)               \n",
    "\n",
    "        self.o1      = nn.Linear(combined, combined)\n",
    "        self.bn1     = nn.BatchNorm1d(combined)\n",
    "        self.relu    = nn.ReLU(combined)\n",
    "\n",
    "        self.o2      = nn.Linear(combined, input_size)\n",
    "        self.bn2     = nn.BatchNorm1d(input_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "        \n",
    "    def forward(self, input, hidden):\n",
    "        combined = torch.cat((input, hidden), 1)    \n",
    "        \n",
    "        hidden   = self.h1(combined)\n",
    "        hidden   = torch.tanh(hidden)\n",
    "        \n",
    "        output   = self.o1(combined)\n",
    "        output   = self.bn1(output)\n",
    "        output   = self.relu(output)\n",
    "        \n",
    "        output   = self.o2(output)\n",
    "        output   = self.bn2(output)\n",
    "        output   = self.softmax(output)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self,bs):\n",
    "        return cuda(torch.zeros(bs,self.hd_sz))\n",
    "\n",
    "def weights_init_uniform(m):\n",
    "    classname = m.__class__.__name__\n",
    "    # for every Linear layer in a model..\n",
    "    if classname.find('Linear') != -1:\n",
    "        # apply a uniform distribution to the weights and a bias=0\n",
    "        m.weight.data.uniform_(0.0, 1.0)\n",
    "        m.bias.data.fill_(0)\n",
    "\n",
    "def weights_init_xavier(m):\n",
    "    classname = m.__class__.__name__\n",
    "    # for every Linear layer in a model..\n",
    "    if classname.find('Linear') != -1:\n",
    "        torch.nn.init.xavier_uniform_(m.weight)\n",
    "        m.bias.data.fill_(0.01)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataLoaders, Itterators, DataSets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad(str_list,sql=1,token='Â£'):\n",
    "    f\"\"\"pad all strings in a list to max_len\"\"\"\n",
    "    max_len = math.ceil(len(max(str_list, key=len))/sql)*sql\n",
    "    for idx, row in enumerate(str_list):        \n",
    "        str_list[idx] = row + token*(max_len-len(row))\n",
    "    if len(str_list) == 1: return str_list[0]\n",
    "    return str_list\n",
    "\n",
    "def mk_tweetbatch(tweets,bs,sql,symbol='Â£'):\n",
    "    assert(math.floor(len(tweets)/bs)==len(tweets)/bs)\n",
    "    assert(math.floor(len(bch[0])/sql)==len(bch[0])/sql)        \n",
    "    bch       = batch_strings(tweets,bs,sql)[0]\n",
    "    n_segment = int(len(bch[0])/sql)\n",
    "    sbx       = torch.zeros(bs,n_segment,sql,len(Data.decoder))\n",
    "    sby       = torch.zeros(bs,n_segment,sql).long()\n",
    "    for tweet in range(bs):\n",
    "        \"\"\"for target we don't use first char, compensate with one padded char\"\"\"\n",
    "        y_str = bch[tweet][1:len(bch[tweet])]+symbol      \n",
    "        \n",
    "        chng_pos = len(bch[tweet])\n",
    "        \"\"\"if we find padded char, we know that tweet ended, remove last char of tweet\"\"\"        \n",
    "        if re.search(symbol,bch[tweet]): chng_pos = re.search(symbol,bch[tweet]).span()[0]       \n",
    "        x_str = change_char(bch[tweet],chng_pos-1,symbol)     \n",
    "        \n",
    "        for segment in range(n_segment):\n",
    "            x = x_str[sql*segment:sql*(segment+1)]\n",
    "            y = y_str[sql*segment:sql*(segment+1)]  \n",
    "            sbx[tweet,segment] = encodestr(x,Data.encoder)\n",
    "            sby[tweet,segment] = torch.Tensor([Data.encoder[char] for char in y])                    \n",
    "    return sbx,sby\n",
    "\n",
    "class TweetDataLoader():\n",
    "    def __init__(self, tweets, bs, sql):    \n",
    "        assert(math.floor(len(tweets)/bs)==len(tweets)/bs)\n",
    "        self.tweets = tweets\n",
    "        self.bs     = bs         \n",
    "        self.sql    = sql\n",
    "        random.shuffle(self.tweets)\n",
    "\n",
    "    def __iter__(self):  \n",
    "        i=-1\n",
    "        while True:\n",
    "            i+=1\n",
    "            twt = self.tweets[i*self.bs:(i+1)*self.bs]\n",
    "            sbx,sby = mk_tweetbatch(twt,self.bs,self.sql)\n",
    "            sbloader = iter(SBDataLoader(sbx,sby))            \n",
    "            yield next(sbloader), True\n",
    "            try:\n",
    "                while True:                \n",
    "                    yield next(sbloader), False \n",
    "            except StopIteration:\n",
    "                pass            \n",
    "            if i==round(len(self.tweets)/self.bs)-1:\n",
    "                random.shuffle(self.tweets)\n",
    "                i=-1\n",
    "\n",
    "class SBDataLoader():\n",
    "    def __init__(self, sbx, sby): \n",
    "        self.sbx, self.sby = sbx, sby\n",
    "    def __iter__(self):\n",
    "        for j in range(self.sbx.shape[1]): yield cuda(self.sbx[:,j]), cuda(self.sby[:,j])\n",
    "\n",
    "def train_model(learner,Params,n_itter,plot_valid=None,hidden=None):\n",
    "#     optimizer = optim.Adam(model.parameters(), lr=Params.lr)\n",
    "    \n",
    "    start = time.time()\n",
    "    if learner.opt is None: learner.opt = optim.RMSprop(learner.model.parameters(), lr=Params.lr)\n",
    "    if plot_valid  is None: plot_valid  = []\n",
    "    if hidden      is None: hidden      = learner.model.initHidden(Params.bs)    \n",
    "        \n",
    "    for i in range(n_itter):\n",
    "        (X,Y), usezerostate     = next(data.train_dl)\n",
    "        if usezerostate: hidden = learner.model.initHidden(Params.bs)\n",
    "\n",
    "        loss = 0\n",
    "        for char in range(X.shape[1]):\n",
    "            x,y = X[:,char],Y[:,char]\n",
    "\n",
    "            f\"\"\"remove padded characters\"\"\"\n",
    "            idx = (y != 0).nonzero()\n",
    "            if idx.shape[0] == 0: break\n",
    "            if idx.shape[0] == 1: idx = idx.squeeze(0)\n",
    "            else:                 idx = idx.squeeze()\n",
    "            hidden = hidden[idx]\n",
    "            x = x[idx]\n",
    "            y = y[idx]\n",
    "            \n",
    "            output,hidden = learner.model.forward(x,hidden)\n",
    "            loss += learner.loss_fn(output,y)\n",
    "        if loss != 0:\n",
    "            loss.backward()\n",
    "            learner.opt.step()\n",
    "            learner.opt.zero_grad()\n",
    "            hidden = hidden.detach()\n",
    "\n",
    "        if i%100==0: \n",
    "            plot_valid.append(get_valid_loss(learner.model,Data,Params,30,50))\n",
    "        if i%500==0: print(f\"\"\"checkpoint: {i} itterations done in {time.time() - start} seconds\"\"\")\n",
    "\n",
    "    print(f\"\"\"this training took {time.time()-start} seconds\"\"\")\n",
    "    return learner,plot_valid,hidden\n",
    "\n",
    "def batch_strings(tweets,bs,sql=1):\n",
    "    f\"\"\"creates a list of batchsize-list of strings of same length and sort each batch with longest string first.\"\"\"    \n",
    "    \"\"\"NOT SURE ABOUT THIS OFFSET, BUT THE PREVIOUS CODE ALWAYS MADE A 0\"\"\"\n",
    "    offset = -1*((len(tweets)/bs)*10%2!=0)    \n",
    "#     offset = -1*((math.floor(len(tweets)/bs)==len(tweets)/bs)==0)    \n",
    "    bch_strs = [] \n",
    "    for i in range(round(len(tweets)/bs)+offset):\n",
    "        strings = tweets[i*bs:(i+1)*bs]\n",
    "        strings.sort(key=len,reverse=True)\n",
    "        pad_strings = pad(strings,sql)\n",
    "        bch_strs.append(pad_strings)\n",
    "    return bch_strs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### building FastAI classes to be used with callbacks in future\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Learner():\n",
    "    def __init__(self, model, opt, loss_fn, data):\n",
    "        self.model,self.opt,self.loss_fn,self.data = model,opt,loss_fn,data\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### start coding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs         = 15\n",
    "data       = pp_trumpdata(path+\"/data/trump/\", [0.9,0.95], bs)\n",
    "Params     = init_params(len(Data.encoder),bs)\n",
    "Params.sql = 30\n",
    "Params.bs  = 15\n",
    "# dataloader = iter(TweetDataLoader(Data.train.tweets,Params.bs,Params.sql))\n",
    "data.train_dl = iter(TweetDataLoader(Data.train.tweets,Params.bs,Params.sql))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint: 0 itterations done in 0.5574395656585693 seconds\n",
      "checkpoint: 500 itterations done in 19.605303525924683 seconds\n",
      "checkpoint: 1000 itterations done in 38.63004684448242 seconds\n",
      "checkpoint: 1500 itterations done in 57.686317443847656 seconds\n",
      "checkpoint: 2000 itterations done in 76.76565647125244 seconds\n",
      "checkpoint: 2500 itterations done in 95.792062997818 seconds\n",
      "checkpoint: 3000 itterations done in 114.81178498268127 seconds\n",
      "checkpoint: 3500 itterations done in 133.78655791282654 seconds\n",
      "checkpoint: 4000 itterations done in 152.7886848449707 seconds\n",
      "checkpoint: 4500 itterations done in 171.69259190559387 seconds\n",
      "checkpoint: 5000 itterations done in 190.93452501296997 seconds\n",
      "checkpoint: 5500 itterations done in 209.95816826820374 seconds\n",
      "checkpoint: 6000 itterations done in 229.0028269290924 seconds\n",
      "checkpoint: 6500 itterations done in 247.9533348083496 seconds\n",
      "checkpoint: 7000 itterations done in 267.03472900390625 seconds\n",
      "checkpoint: 7500 itterations done in 286.04458808898926 seconds\n",
      "checkpoint: 8000 itterations done in 305.0458149909973 seconds\n",
      "checkpoint: 8500 itterations done in 323.95103907585144 seconds\n",
      "checkpoint: 9000 itterations done in 342.9598786830902 seconds\n",
      "checkpoint: 9500 itterations done in 361.95118284225464 seconds\n",
      "this training took 380.3986065387726 seconds\n"
     ]
    }
   ],
   "source": [
    "# plot_valid = []\n",
    "# hidden = None\n",
    "n_itter = 10000\n",
    "\n",
    "# learner = Learner(cuda(RNN(Params.in_sz, Params.hd_sz, 1)),None,nn.NLLLoss(),data)\n",
    "learner,plot_valid,hidden = train_model(learner,Params,n_itter,plot_valid,hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^Harring. I have to a noccoming will be funally &amp; this mediated. https://t.co/9ZkfRH5mour 2nd chatchaty. Today. They are shauner! #Thank whilare on ourly ðŸ‡ºðŸ‡¸-B. Kena. News. Now all is the greatunal,\n"
     ]
    }
   ],
   "source": [
    "generate_seq(rnn,Data,200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2166, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(plot_valid[1:-1])\n",
    "plt.show()\n",
    "print(plot_valid[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "# plt.plot(Plots.valid1[1:-1])\n",
    "plt.plot(Plots.valid2[1:-1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### experimenting with save/load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_checkpoint({\n",
    "            'epoch': epoch,\n",
    "            'arch': \"1_RNN\",\n",
    "            'state_dict': rnn.state_dict(),\n",
    "            'hd_sz': rnn.hd_sz,\n",
    "            'in_sz': rnn.in_sz,\n",
    "            'out_sz': rnn.out_sz,\n",
    "            'loss': loss,\n",
    "            'best_prec1': None,\n",
    "            'optimizer' : None,\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn2, epoch, loss = load_checkpoint(filename='models/checkpoint.pth.tar')\n",
    "rnn2.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### functions I should not need anymore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_parentbatch(tweets, bs, sql, symbol='Â£'):\n",
    "    f\"\"\"each parent-batch will have different numbers of sub-batches depending on how long the tweets are\"\"\"\n",
    "    assert(len(tweets)/bs*10%2==0)\n",
    "    bch_strs = batch_strings(tweets,bs,sql)\n",
    "    parent_batches = []\n",
    "    for pb in range(len(bch_strs)):\n",
    "        bch       = bch_strs[pb]\n",
    "        n_tweet   = bs\n",
    "        n_segment = math.ceil(len(bch[0])/sql)\n",
    "        sbx = torch.zeros(n_tweet,n_segment,sql,len(Data.decoder))\n",
    "        sby = torch.zeros(n_tweet,n_segment,sql).long()\n",
    "\n",
    "        for tweet in range(n_tweet):\n",
    "            if re.search(symbol,bch[tweet]): position = re.search(symbol,bch[tweet]).span()[0]\n",
    "            else:                            position = len(bch[tweet])\n",
    "            x_str = change_char(bch[tweet],position-1,symbol)\n",
    "            y_str = bch[tweet][1:len(bch[tweet])]+symbol                \n",
    "            for segment in range(n_segment):\n",
    "                x = x_str[sql*segment:sql*(segment+1)]\n",
    "                y = y_str[sql*segment:sql*(segment+1)]  \n",
    "                sbx[tweet,segment] = encodestr(x,Data.encoder)\n",
    "                sby[tweet,segment] = torch.Tensor([Data.encoder[char] for char in y])                \n",
    "                \n",
    "        sb_ds = SBDataLoader(sbx, sby)\n",
    "        parent_batches.append(sb_ds)\n",
    "    return parent_batches\n",
    "\n",
    "class ParentDataLoader():\n",
    "    def __init__(self, ds): \n",
    "        self.ds = ds\n",
    "    def __iter__(self):    \n",
    "        for i in range(len(self.ds)):\n",
    "            iterator = iter(self.ds[i])\n",
    "            yield next(iterator), True\n",
    "            try:\n",
    "                while True:                \n",
    "                    yield next(iterator), False \n",
    "            except StopIteration:\n",
    "                pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
