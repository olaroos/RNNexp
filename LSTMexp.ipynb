{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device cuda:0\n",
      "/home/r2/Documents/RNNexp\n"
     ]
    }
   ],
   "source": [
    "from ola_models import * \n",
    "from ola_RNN import * \n",
    "\n",
    "import os, time, copy, math, re, json, pickle, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch, torchvision\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.ticker as ticker\n",
    "%matplotlib inline \n",
    "import seaborn as sns\n",
    "\n",
    "from functools import partial \n",
    "\n",
    "cuda_available = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if cuda_available else \"cpu\")\n",
    "print(f'''using device {device}''')\n",
    "\n",
    "path = !pwd\n",
    "path = path[0]\n",
    "print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.OutputArea.auto_scroll_threshold = 9999;\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.auto_scroll_threshold = 9999;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, x_sz, h_sz, c_sz):\n",
    "        super(LSTM,self).__init__()\n",
    "        self.x_sz = x_sz\n",
    "        self.h_sz = h_sz\n",
    "        self.c_sz = c_sz\n",
    "\n",
    "        self.x_lay = nn.Linear(self.x_sz,4*self.h_sz)                \n",
    "        self.h_lay = nn.Linear(self.h_sz,4*self.h_sz)\n",
    "        self.c_lay = nn.Linear(self.c_sz,2*self.h_sz)\n",
    "        \n",
    "        self.ig_sig = nn.Sigmoid()\n",
    "        self.fg_sig = nn.Sigmoid()\n",
    "        self.og_sig = nn.Sigmoid()\n",
    "        self.gg_tan = nn.Tanh()\n",
    "        \n",
    "        self.softmax = nn.LogSoftmax(dim=1)   \n",
    "            \n",
    "    def forward(self,input,hidd,cell):        \n",
    "        x = self.x_lay(input)   \n",
    "        h = self.h_lay(hidd)           \n",
    "\n",
    "        x_i,x_f,x_o,x_g = x.chunk(4,1)\n",
    "        h_i,h_f,h_o,h_g = h.chunk(4,1)        \n",
    "        \n",
    "        forget_gate = self.fg_sig(x_f + h_f)        \n",
    "        input_gate  = self.ig_sig(x_i + h_i)        \n",
    "        gate_gate   = self.gg_tan(x_g + h_g)         \n",
    "        output_gate = self.ot_sig(x_o + h_o)\n",
    "        \n",
    "        new_cell    = cell * forget_gate + input_gate * gate_gate\n",
    "        new_hidden  = output_gate * torch.tanh(new_cell) \n",
    "                \n",
    "        return self.softmax(torch.cat(x,new_hidden)), (new_hidden, new_cell)\n",
    "    \n",
    "    def batch_forward(self,xb,yb,h_c,loss_fn):        \n",
    "        self.train()\n",
    "        if xb[0,0,1].item() == 1: hidden, cell = self.initHidden(xb.shape[0])\n",
    "        else: hidden,cell = h_c[0],h_c[1]\n",
    "        loss = 0\n",
    "        accu = 0\n",
    "        for char in range(xb.shape[1]):\n",
    "            x,y           = xb[:,char],yb[:,char]\n",
    "            x,y,hidden    = unpad(x,y,hidden)\n",
    "            if x.shape[0] == 0: break\n",
    "            output,hidden,cell = self.forward(x,hidden,cell1)\n",
    "            \"\"\"divide by the bs used for current character\"\"\"\n",
    "            accu += get_accu(output,y)/x.shape[0]    \n",
    "            loss += loss_fn(output,y)\n",
    "        return output,(hidden.detach(),cell.detach()),loss/(char+1),accu/(char+1)\n",
    "\n",
    "    def initHidden(self, bs):\n",
    "        return (cuda(torch.zeros(bs,self.h_sz)), cuda(torch.zeros(bs,self.c_sz)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs  = 30\n",
    "sql = 1000\n",
    "lr  = 0.0005 \n",
    "\n",
    "sched = combine_scheds([0.15, 0.25, 0.2, 0.4], [sched_cos(0.0005, 0.0008), sched_cos(0.0008, 0.0005),sched_lin(0.0005,0.0005),sched_cos(0.0005,0.00005)]) \n",
    "data          = pp_trumpdata(path+\"/data/trump/\", [0.9,0.95], bs)\n",
    "data.train_dl = TweetDataLoader(data,data.train.tweets,bs,sql,shuffle=True)\n",
    "data.valid_dl = TweetDataLoader(data,data.valid.tweets,bs,30,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model  = cuda(LSTM(len(data.decoder), 150, len(data.decoder)))\n",
    "opt    = optim.RMSprop(model.parameters(), lr)\n",
    "learn  = Learner(model,  nn.NLLLoss(), opt , data, lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_rnn(1,learn,cbs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
