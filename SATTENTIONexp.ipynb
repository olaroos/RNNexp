{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device cuda:0\n",
      "/home/r2/Documents/RNNexp\n"
     ]
    }
   ],
   "source": [
    "from ola_models import * \n",
    "from ola_RNN import * \n",
    "\n",
    "import os, time, copy, math, re, json, pickle, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch, torchvision\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.ticker as ticker\n",
    "%matplotlib inline \n",
    "import seaborn as sns\n",
    "\n",
    "from functools import partial \n",
    "\n",
    "cuda_available = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if cuda_available else \"cpu\")\n",
    "print(f'''using device {device}''')\n",
    "\n",
    "path = !pwd\n",
    "path = path[0]\n",
    "print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.OutputArea.auto_scroll_threshold = 9999;\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.auto_scroll_threshold = 9999;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 2, 2]])"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(14) tensor(32) tensor(50)\n",
      "tensor([30, 36, 42])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([[1,2,3],[4,5,6],[7,8,9]])\n",
    "b = a \n",
    "c1 = a[0] @ b[0]\n",
    "c2 = a[1] @ b[0]\n",
    "c3 = a[2] @ b[0]\n",
    "# for i in range(a.shape[0]):            \n",
    "#     w = a[i].t() @ b[0]\n",
    "print(c1,c2,c3)\n",
    "print(a.t() @ b[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = a.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2, 3],\n",
       "         [4, 5, 6],\n",
       "         [7, 8, 9]]])"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a\n",
    "# print(sum(a,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[12, 15, 18]])"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(a,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 14.,  32.,  50.],\n",
      "         [ 32.,  77., 122.],\n",
      "         [ 50., 122., 194.]]], device='cuda:0', dtype=torch.float64)\n",
      "tensor([[2.3195e-16, 1.5230e-08, 1.0000e+00],\n",
      "        [8.1940e-40, 2.8625e-20, 1.0000e+00],\n",
      "        [2.8946e-63, 5.3802e-32, 1.0000e+00]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "tensor(1., device='cuda:0', dtype=torch.float64)\n",
      "torch.Size([3, 3])\n",
      "torch.Size([3])\n",
      "tensor([[2.3195e-16, 8.1940e-40, 2.8946e-63],\n",
      "        [1.5230e-08, 2.8625e-20, 5.3802e-32],\n",
      "        [1.0000e+00, 1.0000e+00, 1.0000e+00]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "tensor(1., device='cuda:0', dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SAttention(nn.Module):\n",
    "    \n",
    "    def __init__(self,x_size):        \n",
    "        super(SAttention,self).__init__()\n",
    "        self.x_size = s_size\n",
    "        # output from query should be [x.shape, x.shape]\n",
    "        # output from query should be the same but this is a problem\n",
    "        # why? because the linear layers only takes a flattened vector as input.          \n",
    "        self.Wq = nn.Linear(self.x_size*self.x_size, self.x_size*self.x_size)         \n",
    "        self.Wk = nn.Linear(self.x_size*self.x_size, self.x_size*self.x_size)\n",
    "        #         \n",
    "        self.Wv = nn.Linear(self.x_size)\n",
    "                        \n",
    "    def self_attention(self,X):\n",
    "        q = self.Wq(torch.flatten(X, start_dim=1))\n",
    "        q = q.reshape(1,self.x_size,self.x_size)\n",
    "        k = self.Wk(torch.flatten(X, start_dim=1))\n",
    "        k = k.reshape(1,self.x_size,self.x_size)        \n",
    "\n",
    "        w_ = torch.bmm(k, q.transpose(1,2))\n",
    "        w  = F.softmax(w_,dim=2)\n",
    "        \n",
    "        v = self.Wv(torch.flatten(X,start_dim=1))\n",
    "        v = v.reshape(1,self.x_size,self.x_size)\n",
    "        \n",
    "        Y = torch.bmm(w,v)\n",
    "        \n",
    "    def self_attention_nolearning(selfm,X):\n",
    "        w_ = torch.bmm(X, X.transpose(1,2))\n",
    "        w  = F.softmax(w_, dim=2)    \n",
    "        Y  = torch.bmm(w, X) \n",
    "        return Y \n",
    "        \n",
    "        \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
